{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ufidon/nlp/blob/main/01.re.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ufidon/nlp/blob/main/01.re.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "# Regular Expressions\n",
    "\n",
    "üìù SALP chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçé An Intriguing Example\n",
    "\n",
    "How do we read and comprehend the text below?\n",
    "- parse sentences, words\n",
    "- search for patterns\n",
    "- recognize name entities\n",
    "- find the meaning of words in their context\n",
    "- feel the sentiment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "John Smith, 123 Main St, Anytown USA 12345\n",
    "Phone: (555) 123-4567\n",
    "Email: [john.smith@example.com](mailto:john.smith@example.com)\n",
    "Occupation: Software Engineer\n",
    "\n",
    "Jane Doe, 456 Elm St, Othertown USA 67890\n",
    "Phone: 1-800-789-0123\n",
    "Email: janedoe@gmail.com\n",
    "Occupation: Marketing Manager\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the following information from this text:\n",
    "\n",
    "* Names (first and last)\n",
    "* Addresses\n",
    "* Phone numbers\n",
    "* Email addresses\n",
    "* Occupations\n",
    "\n",
    "We learn these information subconsciously through **nlp procedures and concepts**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Normalization\n",
    "\n",
    "**Definition:** The process of transforming text into a standard format to prepare it for further processing.\n",
    "\n",
    "**Examples:**\n",
    "- Converting all text to lowercase\n",
    "- Removing punctuation\n",
    "- Expanding contractions (e.g., \"don't\" to \"do not\")\n",
    "\n",
    "\n",
    "\n",
    "## Tokenizing / Tokenization\n",
    "\n",
    "**Definition:** The process of breaking down text into smaller units called tokens, typically words or subwords.\n",
    "\n",
    "**Example:**\n",
    "Input: \"The quick brown fox jumps over the lazy dog.\"\n",
    "Output: [\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog\", \".\"]\n",
    "\n",
    "\n",
    "\n",
    "## Emoticons\n",
    "\n",
    "**Definition:** Textual representations of facial expressions using punctuation and letters.\n",
    "\n",
    "**Examples:**\n",
    "- :) (smile)\n",
    "- :( (sad)\n",
    "- ;) (wink)\n",
    "- :-O (surprised)\n",
    "\n",
    "\n",
    "\n",
    "## Hashtags\n",
    "\n",
    "**Definition:** Words or phrases preceded by a hash sign (#) used to categorize content on social media platforms.\n",
    "\n",
    "**Examples:**\n",
    "- #NaturalLanguageProcessing\n",
    "- #AI\n",
    "- #MachineLearning\n",
    "- #DataScience\n",
    "\n",
    "\n",
    "\n",
    "## Lemmatization\n",
    "\n",
    "**Definition:** The process of reducing words to their base or dictionary form (lemma), considering the context and part of speech.\n",
    "\n",
    "**Examples:**\n",
    "- \"running\" ‚Üí \"run\"\n",
    "- \"better\" ‚Üí \"good\"\n",
    "- \"mice\" ‚Üí \"mouse\"\n",
    "\n",
    "\n",
    "\n",
    "## Lemmatizer\n",
    "\n",
    "**Definition:** A tool or algorithm that performs lemmatization.\n",
    "\n",
    "**Example:**\n",
    "Using NLTK's WordNetLemmatizer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if NLTK is installed on Google Colab\n",
    "import sys\n",
    "in_colab = 'google.colab' in sys.modules\n",
    "nltk_installed = 'nltk' in sys.modules\n",
    "\n",
    "if in_colab and not nltk_installed:\n",
    "    print(\"NLTK is not installed. Installing now...\")\n",
    "    %pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/shanren/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "print(lemmatizer.lemmatize(\"running\", pos=\"v\"))  # Output: \"run\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## Stemming\n",
    "\n",
    "**Definition:** The process of reducing words to their root form by removing affixes, often using heuristic rules.\n",
    "\n",
    "**Examples:**\n",
    "- \"running\" ‚Üí \"run\"\n",
    "- \"happiness\" ‚Üí \"happi\"\n",
    "- \"convertible\" ‚Üí \"convert\"\n",
    "\n",
    "\n",
    "\n",
    "## Sentence Segmentation\n",
    "\n",
    "**Definition:** The process of dividing text into individual sentences.\n",
    "\n",
    "**Example:**\n",
    "Input: \"Mr. Smith bought a new car. It was very expensive. He loves it!\"\n",
    "Output: \n",
    "1. \"Mr. Smith bought a new car.\"\n",
    "2. \"It was very expensive.\"\n",
    "3. \"He loves it!\"\n",
    "\n",
    "\n",
    "\n",
    "## Edit Distance\n",
    "\n",
    "**Definition:** A measure of the minimum number of single-character edits (insertions, deletions, or substitutions) required to change one word into another.\n",
    "\n",
    "**Example:**\n",
    "Edit distance between \"kitten\" and \"sitting\":\n",
    "1. kitten ‚Üí sitten (substitution of \"s\" for \"k\")\n",
    "2. sitten ‚Üí sittin (substitution of \"i\" for \"e\")\n",
    "3. sittin ‚Üí sitting (insertion of \"g\" at the end)\n",
    "\n",
    "Edit distance: 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation in Python regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names:\n",
      "John Smith\n",
      "Main St\n",
      "Anytown USA\n",
      "Software Engineer\n",
      "Jane Doe\n",
      "Elm St\n",
      "Othertown USA\n",
      "Marketing Manager\n",
      "\n",
      "Addresses:\n",
      "123 Main St, Anytown USA 12345\n",
      "456 Elm St, Othertown USA 67890\n",
      "\n",
      "Phone Numbers:\n",
      "(555) 123-4567\n",
      "0-789-0123\n",
      "\n",
      "Email Addresses:\n",
      "john.smith@example.com\n",
      "john.smith@example.com\n",
      "janedoe@gmail.com\n",
      "\n",
      "Occupations:\n",
      "Software Engineer\n",
      "Marketing Manager\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define regex patterns for each piece of information\n",
    "name_pattern = r\"[A-Za-z]+ [A-Za-z]+\"\n",
    "address_pattern = r\"\\d+ [A-Za-z]+ St, [A-Za-z]+ USA \\d{5}\"\n",
    "phone_pattern = r\"\\(\\d{3}\\) \\d{3}-\\d{4}|\\d-\\d{3}-\\d{4}\"\n",
    "email_pattern = r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\"\n",
    "occupation_pattern = r\"Software Engineer|Marketing Manager\"\n",
    "\n",
    "# Use regex to find all occurrences of each pattern\n",
    "names = re.findall(name_pattern, text)\n",
    "addresses = re.findall(address_pattern, text)\n",
    "phones = re.findall(phone_pattern, text)\n",
    "emails = re.findall(email_pattern, text)\n",
    "occupations = re.findall(occupation_pattern, text)\n",
    "\n",
    "# Print the extracted information\n",
    "print(\"Names:\")\n",
    "for name in names:\n",
    "    print(name)\n",
    "\n",
    "print(\"\\nAddresses:\")\n",
    "for address in addresses:\n",
    "    print(address)\n",
    "\n",
    "print(\"\\nPhone Numbers:\")\n",
    "for phone in phones:\n",
    "    print(phone)\n",
    "\n",
    "print(\"\\nEmail Addresses:\")\n",
    "for email in emails:\n",
    "    print(email)\n",
    "\n",
    "print(\"\\nOccupations:\")\n",
    "for occupation in occupations:\n",
    "    print(occupation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regex features used:\n",
    "\n",
    "* Character classes (`[A-Za-z]+`, `\\d+`)\n",
    "* Word boundaries (`\\b`)\n",
    "* Groups (`(\\d{3})`)\n",
    "* Alternation (`|`)\n",
    "* Quantifiers (`*`, `+`, `{5}`)\n",
    "* Anchors (`^`, `$`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Regular Expressions (re)\n",
    "* Regular expressions (regex) are a powerful tool for matching patterns in text data.\n",
    "* In NLP, regex is used for tasks such as:\n",
    "\t+ Text preprocessing\n",
    "\t+ Information extraction\n",
    "\t+ Sentiment analysis\n",
    "\n",
    "## üèÉ [reg101](https://regex101.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "* **Pattern**: A regular expression is a pattern that matches one or more strings of text.\n",
    "* **Literal characters**: Characters that match themselves (e.g. `a` matches the letter \"a\").\n",
    "* **Metacharacters**: Special characters that have special meanings (e.g. `.` matches any single \n",
    "character).\n",
    "* **Escaping**: Using a backslash (`\\`) to treat metacharacters as literal characters.\n",
    "- **Corpus**: A large collection of text where regular expressions are applied for pattern matching.\n",
    "\n",
    "**Example:**\n",
    "- Pattern: `\\bcat\\b`\n",
    "- Corpus: \"The cat sat on the mat.\"\n",
    "- Match: \"cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Special Character** | **Description**                                                    | **Escape Sequence**   | **Example**                        |\n",
    "|-----------------------|--------------------------------------------------------------------|-----------------------|------------------------------------|\n",
    "| `.`                   | Matches any character except newline.                              | `\\.`                  | `a\\.b` matches `a.b`               |\n",
    "| `^`                   | Matches the start of a string.                                     | `\\^`                  | `\\^abc` matches `^abc`             |\n",
    "| `$`                   | Matches the end of a string.                                       | `\\$`                  | `abc\\$` matches `abc$`             |\n",
    "| `*`                   | Matches 0 or more repetitions of the preceding element.            | `\\*`                  | `a\\*b` matches `a*b`               |\n",
    "| `+`                   | Matches 1 or more repetitions of the preceding element.            | `\\+`                  | `a\\+b` matches `a+b`               |\n",
    "| `?`                   | Matches 0 or 1 repetition of the preceding element.                | `\\?`                  | `a\\?b` matches `a?b`               |\n",
    "| `{}`                  | Matches a specified number of repetitions of the preceding element.| `\\{ \\}`              | `a\\{2\\}` matches `a{2}`            |\n",
    "| `[]`                  | Denotes a character class.                                         | `\\[\\]`                | `\\[\\]` matches `[]`                |\n",
    "| `()`                  | Denotes a group or captures the matched content.                   | `\\(\\)`                | `a\\(\\)` matches `a()`              |\n",
    "| `\\|`                   | Acts as an OR operator.                                            | `\\\\|`                  | `a\\\\|b` matches `a\\|b`               |\n",
    "| `\\`                   | Escapes a special character.                                       | `\\\\`                  | `\\\\` matches `\\`                   |\n",
    "| `/`                   | Delimits a regular expression pattern in some languages.           | `\\/`                  | `\\/` matches `/`                   |\n",
    "| `-`                   | Indicates a range in a character class.                            | `\\-`                  | `[a\\-z]` matches `a-z`             |\n",
    "| `:`                   | Used in some special sequences (e.g., POSIX).                      | `\\:`                  | `\\:` matches `:`                   |\n",
    "| `!`                   | Used for negation in some contexts (e.g., negative lookahead).     | `\\!`                  | `\\!` matches `!`                   |\n",
    "| `\"`                   | Used in some contexts, e.g., within JSON.                          | `\\\"`                  | `\\\"` matches `\"`                   |\n",
    "| `'`                   | Used in some contexts, e.g., within JSON.                          | `\\'`                  | `\\'` matches `'`                   |\n",
    "| `#`                   | Used in some languages as a comment character.                     | `\\#`                  | `\\#` matches `#`                   |\n",
    "| `<`                   | Used in lookahead and lookbehind assertions.                       | `\\<`                  | `\\<` matches `<`                   |\n",
    "| `>`                   | Used in lookahead and lookbehind assertions.                       | `\\>`                  | `\\>` matches `>`                   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatenation, Kleene Star, and Kleene Plus\n",
    "\n",
    "**Concatenation**: Combining two or more patterns in sequence.\n",
    "- Example: `a` + `b` matches \"ab\".\n",
    "\n",
    "**Kleene Star (`*`)**: Matches zero or more occurrences of the preceding element.\n",
    "- Example: `a*` matches \"\", \"a\", \"aa\", etc.\n",
    "\n",
    "**Kleene Plus (`+`)**: Matches one or more occurrences of the preceding element.\n",
    "- Example: `a+` matches \"a\", \"aa\", \"aaa\", etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Disjunction, Character Class, and Range\n",
    "\n",
    "**Disjunction (`|`)**: Matches either pattern on its left or right.\n",
    "- Example: `cat|dog` matches \"cat\" or \"dog\".\n",
    "\n",
    "**Character Class**: Matches any one character within a defined set.\n",
    "- Example: `[abc]` matches \"a\", \"b\", or \"c\".\n",
    "\n",
    "**Range**: Shorthand notation for specifying a range of characters.\n",
    "- Example: `[a-z]` matches any lowercase letter from 'a' to 'z'.\n",
    "- `[A-Z]` matches any uppercase letter from 'A' to 'Z'.\n",
    "- `[0-1]` matches any digit from '0' to '9'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| **Special Range** | **Description**                                                                                  | **Example**                      |\n",
    "|-------------------|--------------------------------------------------------------------------------------------------|----------------------------------|\n",
    "| `[a-z]`           | Matches any lowercase letter from a to z.                                                        | `b`, `m`, `z`                    |\n",
    "| `[A-Z]`           | Matches any uppercase letter from A to Z.                                                        | `B`, `M`, `Z`                    |\n",
    "| `[0-9]`           | Matches any digit from 0 to 9.                                                                   | `0`, `5`, `9`                    |\n",
    "| `[a-zA-Z]`        | Matches any letter, whether uppercase or lowercase.                                              | `a`, `Z`                         |\n",
    "| `[a-zA-Z0-9]`     | Matches any alphanumeric character (letters and digits).                                         | `b`, `7`, `Q`                    |\n",
    "| `[aeiou]`         | Matches any vowel.                                                                               | `a`, `e`, `i`                    |\n",
    "| `[^a-z]`          | Matches any character that is not a lowercase letter.                                            | `A`, `7`, `@`                    |\n",
    "| `[\\w]`            | Matches any word character (equivalent to `[a-zA-Z0-9_]`).                                       | `a`, `5`, `_`                    |\n",
    "| `[\\W]`            | Matches any non-word character (equivalent to `[^a-zA-Z0-9_]`).                                  | `@`, `#`, `!`                    |\n",
    "| `[\\d]`            | Matches any digit (equivalent to `[0-9]`).                                                       | `2`, `9`                         |\n",
    "| `[\\D]`            | Matches any non-digit (equivalent to `[^0-9]`).                                                  | `a`, `Q`, `!`                    |\n",
    "| `[\\s]`            | Matches any whitespace character (spaces, tabs, line breaks).                                    | ` `, `\\t`, `\\n`                  |\n",
    "| `[\\S]`            | Matches any non-whitespace character (equivalent to `[^ \\t\\n\\r\\f\\v]`).                           | `A`, `9`, `@`                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchors\n",
    "\n",
    "**Definition:**\n",
    "- **Anchors**: Special characters that match positions within the text rather than actual characters.\n",
    "\n",
    "**Examples:**\n",
    "- `^`: Matches the start of a string.\n",
    "- `$`: Matches the end of a string.\n",
    "- `\\b`: Matches a word boundary.\n",
    "\n",
    "**Example:**\n",
    "- Pattern: `^cat`\n",
    "- Corpus: \"cat is cute.\"\n",
    "- Match: \"cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping, Precedence, and Disjunction\n",
    "\n",
    "**Grouping (`()`)**: Groups patterns and controls operator precedence.\n",
    "- Example: `(cat|dog)s` matches \"cats\" or \"dogs\".\n",
    "\n",
    "**Precedence**: Determines the order in which regular expression operators are evaluated.\n",
    "\n",
    "**Disjunction (`|`)**: Matches either of the patterns in the group.\n",
    "- Example: `cat|dog` matches \"cat\" or \"dog\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## re Operators and Precedence\n",
    "\n",
    "**Operators in Order of Precedence**:\n",
    "1. `()` - Grouping\n",
    "2. `[]` - Character Class\n",
    "3. `*`, `+`, `?` - Quantifiers\n",
    "4. `^`, `$`, `\\b` - Anchors\n",
    "5. `|` - Disjunction\n",
    "\n",
    "**Example:**\n",
    "- Pattern: `a(bc|de)f`\n",
    "- Matches: \"abcf\" or \"adef\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifiers\n",
    "\n",
    "**Definition**: Specifies the number of occurrences of a character or group.\n",
    "\n",
    "**Examples:**\n",
    "- `*`: 0 or more occurrences\n",
    "- `+`: 1 or more occurrences\n",
    "- `?`: 0 or 1 occurrence\n",
    "- `{n}`: Exactly n occurrences\n",
    "- `{n,}`: n or more occurrences\n",
    "- `{n,m}`: Between n and m occurrences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy and Nongreedy Matching\n",
    "\n",
    "**Greedy Matching**: Attempts to match the longest possible string.\n",
    "- Example: `a.*b` matches \"aabcdb\" in \"aabcdb\".\n",
    "\n",
    "**Nongreedy Matching**: Attempts to match the shortest possible string.\n",
    "- Example: `a.*?b` matches \"aab\" in \"aabcdb\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substitution, Capture Groups, and Non-Capturing Groups\n",
    "\n",
    "**Substitution (`re.sub`)**: Replaces matched patterns with a specified replacement.\n",
    "\n",
    "**Capture Groups**: Use `()` to capture a part of the match for later use.\n",
    "- Example: `(\\w+)` captures a word.\n",
    "\n",
    "**Non-Capturing Groups `(?:...)`**: Groups without capturing.\n",
    "- Example: `(?:cat|dog)s` matches \"cats\" or \"dogs\" without capturing \"cat\" or \"dog\".\n",
    "\n",
    "**Example:**\n",
    "- Pattern: `(\\w+)`\n",
    "- Replacement: `\\1-\\1`\n",
    "- Corpus: \"cat\"\n",
    "- Result: \"cat-cat\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regular Expression Substitution\n",
    "\n",
    "```python\n",
    "re.sub(pattern, replacement, string)\n",
    "```\n",
    "\n",
    "- **`pattern`**: The regular expression that defines the text to be matched.\n",
    "- **`replacement`**: The string to replace the matched text.\n",
    "- **`string`**: The input string where the substitution will occur.\n",
    "\n",
    "#### Example 1: Basic Substitution\n",
    "**Goal**: Replace all occurrences of the word \"cat\" with \"dog\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dog sat on the dog mat.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"The cat sat on the cat mat.\"\n",
    "result = re.sub(r'cat', 'dog', text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 2: Substitution with Capture Groups\n",
    "**Goal**: Switch the first and last names in a list of names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doe John, Smith Jane\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"John Doe, Jane Smith\"\n",
    "pattern = r'(\\w+) (\\w+)'\n",
    "replacement = r'\\2 \\1'\n",
    "\n",
    "result = re.sub(pattern, replacement, text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 3: Using Backreferences in Substitution\n",
    "**Goal**: Surround each word with parentheses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(cat) (dog)\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"cat dog\"\n",
    "pattern = r'(\\w+)'\n",
    "replacement = r'(\\1)'\n",
    "\n",
    "result = re.sub(pattern, replacement, text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 4: Substitution with Function\n",
    "**Goal**: Replace each word with its uppercase version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CAT DOG\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"cat dog\"\n",
    "pattern = r'(\\w+)'\n",
    "\n",
    "def to_upper(match):\n",
    "    return match.group(1).upper()\n",
    "\n",
    "result = re.sub(pattern, to_upper, text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 5: Limiting the Number of Substitutions\n",
    "**Goal**: Replace only the first occurrence of \"cat\" with \"dog\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dog cat cat\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"cat cat cat\"\n",
    "result = re.sub(r'cat', 'dog', text, count=1)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example 6: Non-Capturing Groups in Substitution\n",
    "**Goal**: Replace \"Mr.\" and \"Ms.\" with \"Mx.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mx. John Doe, Mx. Jane Doe\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "text = \"Mr. John Doe, Ms. Jane Doe\"\n",
    "pattern = r'(?:Mr|Ms)\\.'\n",
    "replacement = r'Mx.'\n",
    "\n",
    "result = re.sub(pattern, replacement, text)\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lookahead Assertions\n",
    "\n",
    "**Lookahead**: Asserts that a pattern follows the current position without consuming characters.\n",
    "\n",
    "**Positive Lookahead (`(?=...)`)**:\n",
    "- Example: `\\w+(?=\\d)` matches a word followed by a digit.\n",
    "\n",
    "**Negative Lookahead (`(?!...)`)**:\n",
    "- Example: `\\w+(?!\\d)` matches a word not followed by a digit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## False Positives and False Negatives in Matching, Precision and Recall\n",
    "\n",
    "**False Positives**: Matches that are incorrect.\n",
    "**False Negatives**: Failing to match a correct pattern.\n",
    "\n",
    "**Precision**: Ratio of true positives to all matches.\n",
    "**Recall**: Ratio of true positives to all actual positives.\n",
    "\n",
    "**Example:**\n",
    "- Pattern: `cat`\n",
    "- Corpus: \"The catalog is here.\"\n",
    "- False Positive: \"catalog\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comprehensive Example\n",
    "\n",
    "**Pattern**: `^(Mr|Ms|Dr)\\.?\\s(\\w+)\\s(\\w+)$`\n",
    "**Explanation**:\n",
    "- `^` asserts the start of the string.\n",
    "- `(Mr|Ms|Dr)` matches \"Mr\", \"Ms\", or \"Dr\".\n",
    "- `\\.?` optionally matches a period.\n",
    "- `\\s` matches a whitespace character.\n",
    "- `(\\w+)` captures the first and last name.\n",
    "\n",
    "**Example Corpus**: \"Dr. John Doe\"\n",
    "**Match**: \"Dr. John Doe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Dr, First Name: John, Last Name: Doe\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Comprehensive pattern\n",
    "pattern = r\"^(Mr|Ms|Dr)\\.?\\s(\\w+)\\s(\\w+)$\"\n",
    "\n",
    "# Sample text\n",
    "text = \"Dr. John Doe\"\n",
    "\n",
    "# Match\n",
    "match = re.match(pattern, text)\n",
    "\n",
    "if match:\n",
    "    title = match.group(1)\n",
    "    first_name = match.group(2)\n",
    "    last_name = match.group(3)\n",
    "    print(f\"Title: {title}, First Name: {first_name}, Last Name: {last_name}\")\n",
    "else:\n",
    "    print(\"No match found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîó [re ‚Äî Regular expression operations](https://docs.python.org/3/library/re.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üèÉ Practice\n",
    "- Play common Python regexes on [reg101](https://regex101.com/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçé Define a pattern to match the word \"good\" through refinement\n",
    "\n",
    "\n",
    "### Step 1: Basic Matching\n",
    "\n",
    "```regex\n",
    "good\n",
    "```\n",
    "\n",
    "- It matches the exact sequence of characters \"good\" in the text.\n",
    "\n",
    "### Step 2: Word Boundaries\n",
    "- Avoid matching words like \"goodbye\" or \"goodness\".\n",
    "\n",
    "```regex\n",
    "\\bgood\\b\n",
    "```\n",
    "\n",
    "### Step 3: Case Insensitivity\n",
    "- Allow match good with any sensitivity\n",
    "\n",
    "```regex\n",
    "(?i)\\bgood\\b\n",
    "```\n",
    "\n",
    "- `(?i)` is a case-insensitive flag, making the match case-insensitive.\n",
    "\n",
    "### Step 4: Handling Optional Characters\n",
    "- Handle cases where there might be optional characters like punctuation or a trailing \"s\", such as \"good!\" or \"goods\".\n",
    "\n",
    "```regex\n",
    "(?i)\\bgood\\b[^\\w]?\n",
    "```\n",
    "\n",
    "- `[^\\w]?` matches an optional non-word character (like punctuation) after \"good\".\n",
    "\n",
    "### Step 5: Match Variations (Optional)\n",
    "- Expand the pattern to match variations or synonyms of \"good\" if needed.\n",
    "\n",
    "```regex\n",
    "(?i)\\b(good|great|excellent)\\b\n",
    "```\n",
    "\n",
    "\n",
    "### Step 6: Full Refinement\n",
    "- Handle standalone word \n",
    "\n",
    "```regex\n",
    "(?i)\\bgood\\b([^\\w]|$)\n",
    "```\n",
    "\n",
    "### Example Use\n",
    "Here‚Äôs how the refined pattern works with various inputs:\n",
    "\n",
    "- **Input:** \"Good job!\"\n",
    "  - **Matches:** \"Good\"\n",
    "  \n",
    "- **Input:** \"The goods are here.\"\n",
    "  - **Doesn't Match:** \"goods\" (since it's part of another word)\n",
    "\n",
    "- **Input:** \"She is a good person.\"\n",
    "  - **Matches:** \"good\"\n",
    "\n",
    "- **Input:** \"GOOD.\"\n",
    "  - **Matches:** \"GOOD\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Regex in NLP\n",
    "* **Preprocessing text data**: Use regex to remove punctuation, convert to lowercase, etc.\n",
    "* **Extracting information**: Use regex to extract specific patterns from text data (e.g. phone \n",
    "numbers, email addresses).\n",
    "* **Sentiment analysis**: Use regex to extract sentiment-bearing phrases from text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçé Example\n",
    "Text Analysis with NLTK:\n",
    "\n",
    "* Tokenize the text into individual words and sentences\n",
    "* Perform stemming on the tokens (i.e., reduce words to their base form)\n",
    "* Identify named entities in the text (e.g., people, places, organizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens:\n",
      "John\n",
      "Smith\n",
      ",\n",
      "123\n",
      "Main\n",
      "St\n",
      ",\n",
      "Anytown\n",
      "USA\n",
      "12345\n",
      "Phone\n",
      ":\n",
      "(\n",
      "555\n",
      ")\n",
      "123-4567\n",
      "Email\n",
      ":\n",
      "[\n",
      "john.smith\n",
      "@\n",
      "example.com\n",
      "]\n",
      "(\n",
      "mailto\n",
      ":\n",
      "john.smith\n",
      "@\n",
      "example.com\n",
      ")\n",
      "Occupation\n",
      ":\n",
      "Software\n",
      "Engineer\n",
      "Jane\n",
      "Doe\n",
      ",\n",
      "456\n",
      "Elm\n",
      "St\n",
      ",\n",
      "Othertown\n",
      "USA\n",
      "67890\n",
      "Phone\n",
      ":\n",
      "1-800-789-0123\n",
      "Email\n",
      ":\n",
      "janedoe\n",
      "@\n",
      "gmail.com\n",
      "Occupation\n",
      ":\n",
      "Marketing\n",
      "Manager\n",
      "\n",
      "Sentence Tokens:\n",
      "\n",
      "John Smith, 123 Main St, Anytown USA 12345\n",
      "Phone: (555) 123-4567\n",
      "Email: [john.smith@example.com](mailto:john.smith@example.com)\n",
      "Occupation: Software Engineer\n",
      "\n",
      "Jane Doe, 456 Elm St, Othertown USA 67890\n",
      "Phone: 1-800-789-0123\n",
      "Email: janedoe@gmail.com\n",
      "Occupation: Marketing Manager\n",
      "\n",
      "Stemmed Words:\n",
      "john\n",
      "smith\n",
      ",\n",
      "123\n",
      "main\n",
      "st\n",
      ",\n",
      "anytown\n",
      "usa\n",
      "12345\n",
      "phone\n",
      ":\n",
      "(\n",
      "555\n",
      ")\n",
      "123-4567\n",
      "email\n",
      ":\n",
      "[\n",
      "john.smith\n",
      "@\n",
      "example.com\n",
      "]\n",
      "(\n",
      "mailto\n",
      ":\n",
      "john.smith\n",
      "@\n",
      "example.com\n",
      ")\n",
      "occup\n",
      ":\n",
      "softwar\n",
      "engin\n",
      "jane\n",
      "doe\n",
      ",\n",
      "456\n",
      "elm\n",
      "st\n",
      ",\n",
      "othertown\n",
      "usa\n",
      "67890\n",
      "phone\n",
      ":\n",
      "1-800-789-0123\n",
      "email\n",
      ":\n",
      "janedo\n",
      "@\n",
      "gmail.com\n",
      "occup\n",
      ":\n",
      "market\n",
      "manag\n",
      "\n",
      "Named Entities:\n",
      "PERSON: John \n",
      "GPE: Smith \n",
      "PERSON: Anytown \n",
      "PERSON: Software Engineer Jane Doe \n",
      "PERSON: Othertown \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "# Download required NLTK data if necessary\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "\n",
    "# use the same text as above\n",
    "# text = \"\"\"\n",
    "# The quick brown fox jumps over the lazy dog. The sun is shining brightly today.\n",
    "# \"\"\"\n",
    "\n",
    "# Tokenize the text into individual words and sentences\n",
    "word_tokens = word_tokenize(text)\n",
    "sentence_tokens = sent_tokenize(text)\n",
    "\n",
    "print(\"Word Tokens:\")\n",
    "for token in word_tokens:\n",
    "    print(token)\n",
    "\n",
    "print(\"\\nSentence Tokens:\")\n",
    "for sentence in sentence_tokens:\n",
    "    print(sentence)\n",
    "\n",
    "# Perform stemming on the tokens\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in word_tokens]\n",
    "\n",
    "print(\"\\nStemmed Words:\")\n",
    "for stemmed_word in stemmed_words:\n",
    "    print(stemmed_word)\n",
    "\n",
    "# Identify named entities in the text\n",
    "tagged_text = nltk.pos_tag(word_tokenize(text))\n",
    "named_entities = ne_chunk(tagged_text)\n",
    "\n",
    "print(\"\\nNamed Entities:\")\n",
    "for tree in named_entities:\n",
    "    if hasattr(tree, 'label'):\n",
    "        print(tree.label(), end=': ')\n",
    "        for leaf in tree.leaves():\n",
    "            print(leaf[0], end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK features used:\n",
    "\n",
    "* Tokenization (`word_tokenize`, `sent_tokenize`)\n",
    "* Stemming (`PorterStemmer`)\n",
    "* Part-of-speech tagging (`pos_tag`)\n",
    "* Named entity recognition (`ne_chunk`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîó [Natural Language Toolkit](https://www.nltk.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçé Application: ELIZA Chatbot\n",
    "\n",
    "### What is ELIZA?\n",
    "- ELIZA: Early Language Intelligent System Attempt\n",
    "- A pioneering chatbot in artificial intelligence\n",
    "- An early natural language processing computer program\n",
    "- Created by Joseph Weizenbaum at MIT from 1964 to 1966\n",
    "- One of the first chatbots in the history of artificial intelligence\n",
    "\n",
    "\n",
    "### How ELIZA Works\n",
    "\n",
    "1. Uses pattern matching and substitution methodology\n",
    "2. Simulates conversation by using pre-programmed responses\n",
    "3. Aims to engage users in a manner similar to a Rogerian psychotherapist\n",
    "\n",
    "\n",
    "### Key Features\n",
    "\n",
    "- Keyword identification\n",
    "- Contextual pattern matching\n",
    "- Transformation rules to convert input to output\n",
    "- Ability to maintain a conversational state\n",
    "\n",
    "\n",
    "### Historical Significance\n",
    "\n",
    "- Demonstrated the potential of human-computer interaction\n",
    "- Sparked discussions about AI and its implications\n",
    "- Influenced development of subsequent chatbots and conversational AI\n",
    "\n",
    "\n",
    "### Legacy and Impact\n",
    "\n",
    "- Raised questions about the nature of intelligence and understanding\n",
    "- Contributed to ongoing debates in AI ethics and philosophy\n",
    "- Inspired further research in natural language processing and AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üçé [A simple ELIZA](https://stackoverflow.com/questions/54777612/regex-python-rule-based-eliza-implementation)\n",
    "- [code](./codes/01/seliza.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîó [Eliza chatbot in Python](https://github.com/wadetb/eliza)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
