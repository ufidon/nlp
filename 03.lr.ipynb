{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ufidon/nlp/blob/main/03.lr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ufidon/nlp/blob/main/03.lr.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "# Logistic Regression\n",
    "\n",
    "üìù SALP chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Generative Classifier: Naive Bayes**\n",
    "- Models $P(x | y)$ and $P(y)$, then applies Bayes‚Äô Theorem to compute $P(y | x)$.\n",
    "  - $P(y | x) \\propto P(x | y) P(y)$\n",
    "  - Assumes feature independence (Naive Bayes assumption).\n",
    "- **Generative model** ‚Äî can simulate data points.\n",
    "- **Types**:\n",
    "  - **Multinomial Naive Bayes**: Used for text classification (e.g., spam detection).\n",
    "  - **Gaussian Naive Bayes**: Used for continuous data.\n",
    "\n",
    "\n",
    "### **Classifier Types**\n",
    "- **Generative**: Model how data is generated (`Naive Bayes`)\n",
    "- **Discriminative**: Directly model decision boundary (`Logistic Regression`)\n",
    "\n",
    "\n",
    "### **Discriminative Classifier: Logistic Regression**\n",
    "  - Directly models $P(y | x)$ ‚Äî the probability of the label $y$ given the features $x$.\n",
    "    - $\\displaystyle P(y=1 | x) = \\frac{1}{1 + e^{-(\\theta^T x)}}$\n",
    "    - **Sigmoid function** for binary classification.\n",
    "  - **Decision boundary-based**.\n",
    "    - Does not assume underlying data distribution.\n",
    "- **Common Uses**:\n",
    "  - Binary and multiclass classification.\n",
    "  - Sentiment analysis, spam filtering.\n",
    "\n",
    "\n",
    "### **Mathematical Comparison**\n",
    "| **Aspect**     | **Logistic Regression**    | **Naive Bayes**    |\n",
    "|-------------|---------------|------------------------|\n",
    "| **Model Type**  | Discriminative     | Generative       |\n",
    "| **Estimates**    | $P(y \\| x)$ directly    | $P(x \\| y)$ and $P(y)$      |\n",
    "| **Feature Dependence**| No assumptions  | Assumes conditional independence   |\n",
    "| **Computational Cost**| Generally higher    | Often faster for high-dimensional data |\n",
    "| **Training Data Requirements** | Larger datasets for accuracy | Can work well with small datasets  |\n",
    "| **Strengths** | ‚ñ∑ Flexible with features.<br>‚ñ∑ Robust to correlated features.‚ñ∑ Directly optimizes decision boundary. | ‚ñ∑ Simple and fast, even with smaller datasets.<br>‚ñ∑ Good for text classification with a high number of features |\n",
    "| **Weaknesses** | ‚ñ∑ Requires larger datasets.<br>‚ñ∑ Can overfit without regularization. | ‚ñ∑ Assumption of feature independence is often unrealistic.<br>‚ñ∑ Can underperform when features are highly correlated. |\n",
    "| **Use cases** | ‚ñ∑ Large datasets with many features.<br>‚ñ∑ Features that are highly correlated.<br>‚ñ∑ A need for direct probability estimates. |‚ñ∑ Smaller datasets.<br>‚ñ∑ Assumption of feature independence is reasonable (e.g., bag of words in text).<br>‚ñ∑ A need for quick and simple model deployment.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Components of a Probabilistic Classifier**\n",
    "- Machine learning classifiers like **naive Bayes** and **logistic regression** are probabilistic classifiers that use **supervised learning**.\n",
    "- They require a **training corpus** of $m$ input/output pairs: $(x^{(i)}, y^{(i)})$, where $x^{(i)}$ is an input observation and $y^{(i)}$ is the class label.\n",
    "\n",
    "\n",
    "### **Training Corpus**\n",
    "- In **sentiment classification**, $x^{(i)}$ might represent a document, and $y^{(i)}$ its sentiment label (positive or negative).\n",
    "  - Superscripts in parentheses refer to individual instances.\n",
    "- **Data Example Table:**\n",
    "  - $x^{(1)}$: \"The movie was great!\" ‚Üí $y^{(1)} = 1$ (positive).\n",
    "  - $x^{(2)}$: \"The movie was terrible.\" ‚Üí $y^{(2)} = 0$ (negative).\n",
    "\n",
    "\n",
    "### **Key Components of a Classifier**\n",
    "1. **Feature Representation** of the input.\n",
    "   - It turns inputs into structured data.\n",
    "2. **Classification Function** to estimate $\\hat{y}$ based on $p(y|x)$.\n",
    "   - It computes class probabilities.\n",
    "3. **Objective Function** for minimizing error.\n",
    "   - It measures how well the model performs.\n",
    "4. **Optimization Algorithm** to train the model.\n",
    "   - It is used to optimize the model during training.\n",
    "\n",
    "\n",
    "### **1. Feature Representation of the Input**\n",
    "- For each input observation $x^{(i)}$, represent it as a **vector of features**: $[x_1, x_2, \\dots, x_n]$.\n",
    "  - For instance $j$, **feature** $i$ is represented as $x_i^{(j)}$ or simplified as $x_i$.\n",
    "- In multiclass classification, features may be noted as $f_i(c, x)$, where $c$ represents the class.\n",
    "\n",
    "\n",
    "\n",
    "### **2. Classification Function**\n",
    "- The classification function computes the **estimated class** $\\hat{y}$ using $p(y|x)$, the probability of $y$ given $x$.\n",
    "- **Logistic regression** uses the **sigmoid function** for binary classification, while **softmax** is used for multiclass classification.\n",
    "\n",
    "- For binary classification: $p(y=1|x) = \\dfrac{1}{1 + e^{-(w^T \\cdot x + b)}}$ (sigmoid).\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### **3. Objective Function**\n",
    "- We define an **objective function** to optimize, which typically involves minimizing a **loss function** that measures classification error.\n",
    "- In logistic regression, this is the **cross-entropy loss function**.\n",
    "\n",
    "- Binary Cross-Entropy Loss: $\\mathcal{L} = - [ y \\log(\\hat{y}) + (1 - y) \\log(1 - \\hat{y}) ]$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### **4. Optimization Algorithm**\n",
    "- The optimization algorithm aims to minimize the objective function, updating the model parameters.\n",
    "- **Stochastic Gradient Descent (SGD)** is commonly used for this task.\n",
    "- SGD process:\n",
    "  - Initialize weights.\n",
    "  - Loop over training data: compute gradient, update weights.\n",
    "  - Repeat until convergence.\n",
    "\n",
    "\n",
    "\n",
    "### **Logistic Regression Phases**\n",
    "- **Training Phase:**\n",
    "  - Train the system by learning the **weights** $w$ and **bias** $b$ using stochastic gradient descent and minimizing the cross-entropy loss.\n",
    "  - Weight update: $w = w - \\eta \\nabla \\mathcal{L}$\n",
    "- **Testing Phase:**\n",
    "  - Given a test example $x$, compute $p(y|x)$ and return the label with the **higher probability**: $y = 1$ or $y = 0$.\n",
    "\n",
    "\n",
    "### **Test Example**\n",
    "- Input: \"The product is amazing!\" (vectorized features).\n",
    "- Logistic regression computes the probability of sentiment being **positive** or **negative**.\n",
    "- Output: $p(\\text{positive} | x) = 0.85$, so the system predicts **positive** sentiment $(y=1)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Binary Logistic Regression**\n",
    "- **Goal:**\n",
    "  - Train a classifier that can make a **binary decision** about the class of a new input.\n",
    "- **Example:**\n",
    "  - $y = 1$: Positive class (e.g., positive sentiment).\n",
    "  - $y = 0$: Negative class (e.g., negative sentiment).\n",
    "- **Objective:**\n",
    "  - Estimate $P(y = 1 | x)$, the probability that the input belongs to class 1.\n",
    "\n",
    "\n",
    "### **Input Representation in Logistic Regression**\n",
    "- **Input Observation $x$:**\n",
    "  - Represented as a **vector of features**: $[x_1, x_2, \\dots, x_n]$.\n",
    "- **Example:**\n",
    "  - For sentiment classification, $x$ could represent word counts in a document\n",
    "    - e.g., \"awesome\" vs. \"abysmal\".\n",
    "\n",
    "\n",
    "### **Logistic Regression Classifier**\n",
    "- **Weights and Bias:**\n",
    "  - Logistic regression learns a **weight** $w_i$ for each feature $x_i$, and a **bias term** $b$.\n",
    "  - **Weight $w_i$:**\n",
    "    - Positive: Evidence that the input belongs to the positive class.\n",
    "    - Negative: Evidence that the input belongs to the negative class.\n",
    "- **Example:**\n",
    "  - \"awesome\" ‚Üí high positive weight $w_{\\text{awesome}}$.\n",
    "  - \"abysmal\" ‚Üí high negative weight $w_{\\text{abysmal}}$.\n",
    "\n",
    "\n",
    "### **Calculating the Score $z$**\n",
    "- **Weighted Sum of Features:**\n",
    "  - The classifier calculates the score $z$, the **weighted sum** of the features plus the bias:\n",
    "    - $\\displaystyle z = \\sum_{i=1}^{n} w_i x_i + b$\n",
    "  - **Dot Product Notation:**\n",
    "    - $z = w \\cdot x + b$\n",
    "\n",
    "\n",
    "### **From Score to Probability**\n",
    "- **Problem:**\n",
    "  - $z$ can range from $-\\infty$ to $+\\infty$, but we need a **probability** between 0 and 1.\n",
    "- **Solution:**\n",
    "  - Use the **sigmoid function** to convert $z$ to a probability.\n",
    "    - $\\sigma(z) = \\dfrac{1}{1 + e^{-z}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Generate values for z\n",
    "z_values = np.linspace(-10, 10, 100)\n",
    "sigmoid_values = sigmoid(z_values)\n",
    "\n",
    "# Plot sigmoid function\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(z_values, sigmoid_values, label=r'$\\sigma(z) = \\dfrac{1}{1 + e^{-z}}$', color='blue')\n",
    "plt.axhline(0.5, color='gray', linestyle='--', label='y = 0.5')\n",
    "plt.title('Sigmoid Function')\n",
    "plt.xlabel('z')\n",
    "plt.ylabel(r'$\\sigma(z)$')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### **Sigmoid Function: Interpretation**\n",
    "- Converts real-valued numbers into the range $(0, 1)$.\n",
    "- **Nearly linear** around 0 but **squashes** outliers toward 0 or 1.\n",
    "- **Differentiable**, which is important for optimization.\n",
    "\n",
    "\n",
    "### **Calculating Probabilities**\n",
    "- **Positive Class Probability:**\n",
    "  $P(y = 1 | x) = \\sigma(w \\cdot x + b) = \\dfrac{1}{1 + e^{-(w \\cdot x + b)}}$\n",
    "- **Negative Class Probability:**\n",
    "  $P(y = 0 | x) = 1 - \\sigma(w \\cdot x + b) = \\dfrac{e^{-(w \\cdot x + b)}}{1 + e^{-(w \\cdot x + b)}}$\n",
    "\n",
    "\n",
    "### **Sigmoid Function Properties**\n",
    "- **Key Property:**\n",
    "  - $1 - \\sigma(x) = \\sigma(-x)$\n",
    "  - This allows us to express $P(y = 0)$ as $\\sigma(-(w \\cdot x + b))$.\n",
    "- **Logit Function:**\n",
    "  - The input to the sigmoid $z = w \\cdot x + b$ is called the **logit**.\n",
    "  - The **logit function** is the **inverse of the sigmoid**:\n",
    "  - $\\text{logit}(p) = \\sigma^{-1}(p) = \\ln\\left(\\dfrac{p}{1 - p}\\right)$\n",
    "\n",
    "\n",
    "## üçé **Binary Sentiment Classification**\n",
    "- **Task:** Predict the sentiment of a review.\n",
    "- **Input:** Feature vector $x$ representing word counts.\n",
    "- **Model:** Logistic regression with learned weights.\n",
    "- **Score Calculation:** \n",
    "  - $z = w \\cdot x + b$\n",
    "  - $z = w^T x + b$ (linear combination of weights and features)\n",
    "  - $w = [w_1, w_2, ..., w_n]$ is the weight vector\n",
    "  - $x = [x_1, x_2, ..., x_n]$ are the features\n",
    "  - $b$ is the bias term.\n",
    "- **Probability Calculation:**\n",
    "  - $P(\\text{positive} | x) = \\sigma(z)$\n",
    "- **Decision:** If $P(\\text{positive} | x) > 0.5$, predict positive sentiment.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Step 1: Sample Product Reviews**\n",
    "\n",
    "Consider these three sample product reviews:\n",
    "\n",
    "1. **Review 1**: \"I love this product! It's amazing and works perfectly.\"\n",
    "2. **Review 2**: \"This is the worst product I have ever used. I hate it!\"\n",
    "3. **Review 3**: \"It's okay, but I've seen better.\"\n",
    "\n",
    "### **Step 2: Manually Extract Features**\n",
    "We need to manually extract features from the reviews. Let's use the following features:\n",
    "- $x_1$ - **Count of positive words** (e.g., love, amazing, perfect, etc.)\n",
    "- $x_2$ - **Count of negative words** (e.g., worst, hate, bad, etc.)\n",
    "- $x_3$ - **Presence of exclamation marks** (1 if any, 0 otherwise)\n",
    "- $x_4$ - **Log of total word count**\n",
    "\n",
    "| Review     | Positive Words | Negative Words | Exclamations | Log Word Count |\n",
    "|------------|----------------|----------------|--------------|----------------|\n",
    "| Review 1   | 3              | 0              | 1            | 2.19           |\n",
    "| Review 2   | 0              | 2              | 1            | 2.48           |\n",
    "| Review 3   | 0              | 0              | 0            | 1.79           |\n",
    "\n",
    "### **Step 3: Define Weights**\n",
    "Assume we have pre-trained weights from a logistic regression model:\n",
    "- $w = [2.5, -4.0, 1.2, 0.6]$ (weights for positive words, negative words, exclamations, and log word count)\n",
    "- $b = 0.2$ (bias term)\n",
    "\n",
    "### **Step 4: Manually Perform the Calculation**\n",
    "- $z = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + b$\n",
    "#### **Review 1 Calculation**:\n",
    "- $z = 2.5 \\times 3 + (-4.0) \\times 0 + 1.2 \\times 1 + 0.6 \\times 2.19 + 0.2$\n",
    "- $z = 7.5 + 0 + 1.2 + 1.314 + 0.2 = 10.214$\n",
    "- Probability $P(y = 1 | x) = \\sigma(10.214) = \\dfrac{1}{1 + e^{-10.214}} = \\approx 1$ (Positive sentiment)\n",
    "\n",
    "#### **Review 2 Calculation**:\n",
    "- $z = 2.5 \\times 0 + (-4.0) \\times 2 + 1.2 \\times 1 + 0.6 \\times 2.48 + 0.2$\n",
    "- $z = 0 - 8 + 1.2 + 1.488 + 0.2 = -5.112$\n",
    "- Probability $P(y = 1 | x) = \\sigma(-5.112) \\approx 0.006$ (Negative sentiment)\n",
    "\n",
    "#### **Review 3 Calculation**:\n",
    "- $z = 2.5 \\times 0 + (-4.0) \\times 0 + 1.2 \\times 0 + 0.6 \\times 2.40 + 0.2$\n",
    "- $z = 0 - 0 + 0 + 1.44 + 0.2 = 1.64$\n",
    "- Probability $P(y = 1 | x) = \\sigma(1.64) \\approx 0.837$ (Positive sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import re\n",
    "\n",
    "# Step 1: Define lists of positive and negative words\n",
    "positive_words = {\"love\", \"amazing\", \"perfect\", \"perfectly\", \"great\", \"good\", \"excellent\", \"like\"}\n",
    "negative_words = {\"worst\", \"hate\", \"bad\", \"terrible\", \"awful\", \"poor\", \"dislike\"}\n",
    "\n",
    "# Step 2: Function to extract features from a review\n",
    "def extract_features(review):\n",
    "    # Clean the review (remove punctuation and convert to lowercase)\n",
    "    review_clean = re.sub(r'[^\\w\\s]', '', review.lower())\n",
    "    words = review_clean.split()\n",
    "\n",
    "\n",
    "    # Feature 1: Count of positive words\n",
    "    positive_count = sum(1 for word in words if word in positive_words)\n",
    "    \n",
    "    # Feature 2: Count of negative words\n",
    "    negative_count = sum(1 for word in words if word in negative_words)\n",
    "    \n",
    "    # Feature 3: Presence of exclamation marks\n",
    "    exclamation_count = 1 if \"!\" in review else 0\n",
    "    \n",
    "    # Feature 4: Log of total word count\n",
    "    word_count = len(words)\n",
    "    print(f'\\n{review}\\n{review_clean}\\n{words}\\n{word_count}')\n",
    "\n",
    "    log_word_count = math.log(word_count) if word_count > 0 else 0\n",
    "    \n",
    "    # Return the features as a list\n",
    "    return [positive_count, negative_count, exclamation_count, log_word_count]\n",
    "\n",
    "# Step 3: List of sample reviews\n",
    "reviews = [\n",
    "    \"I love this product! It's amazing and works perfectly.\",  # Review 1\n",
    "    \"This is the worst product I have ever used. I hate it!\",  # Review 2\n",
    "    \"It's okay, but I've seen better.\"                         # Review 3\n",
    "]\n",
    "\n",
    "# Step 4: Extract features for each review\n",
    "feature_matrix = np.array([extract_features(review) for review in reviews])\n",
    "\n",
    "# Step 5: Define weights and bias (as provided)\n",
    "weights = np.array([2.5, -4.0, 1.2, 0.6])\n",
    "bias = 0.2\n",
    "\n",
    "# Step 6: Sigmoid function\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "# Step 7: Calculate z for each review\n",
    "z_values = np.dot(feature_matrix, weights) + bias\n",
    "\n",
    "# Step 8: Apply sigmoid to get probabilities\n",
    "probabilities = sigmoid(z_values)\n",
    "\n",
    "# Step 9: Classify based on probabilities (threshold = 0.5)\n",
    "classifications = (probabilities > 0.5).astype(int)\n",
    "\n",
    "# Step 10: Output the results\n",
    "for i, (prob, classification) in enumerate(zip(probabilities, classifications), 1):\n",
    "    sentiment = \"Positive\" if classification == 1 else \"Negative\"\n",
    "    print(f\"Review {i}: Probability of positive sentiment = {prob:.4f}, Classification = {sentiment}\")\n",
    "\n",
    "# Optional: Display extracted features\n",
    "print(\"\\nExtracted Feature Matrix (Positive Words, Negative Words, Exclamations, Log Word Count):\")\n",
    "print(feature_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
