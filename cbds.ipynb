{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ufidon/nlp/blob/main/cbds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ufidon/nlp/blob/main/cbds.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "**Chatbots & Dialogue Systems**\n",
    "\n",
    "- üìù SALP chapter 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- `Conversation` is a foundational aspect of language, learned early and used widely, driving the design of `interactive programs` such as \n",
    "  - `frame-based` dialogue systems for `structured tasks` \n",
    "  - `chatbots` for more flexible, `unstructured` conversations\n",
    "  - many modern systems blend both, as seen in tools like Siri and ChatGPT.\n",
    "\n",
    "- Early chatbot ELIZA, designed to simulate a therapist, used `simple pattern-matching and regular expressions`, creating responses that seemed personalized and led users to feel emotionally connected.\n",
    "  - Its responses were crafted based on `specific keywords`, allowing the system to adapt replies to certain words for more engaging interactions, sometimes using `general responses` when no keywords were matched.\n",
    "  - It demonstrated that users could become emotionally involved, often treating the system as a human, which led to behaviors typical of human interactions, like sharing personal issues.\n",
    "\n",
    "- `Emotional attachment` to chatbots raises privacy concerns; \n",
    "  - users tend to disclose private information more freely, increasing risks, especially when the chatbot seems more human-like.\n",
    "  - Privacy and emotional impact require careful consideration when designing and deploying chatbots,\n",
    "    - as they may inadvertently influence users' emotional well-being and cognitive states.\n",
    "- Chatbot usage, especially in `sensitive areas`, may need oversight, such as Institutional Review Board (IRB) approval, to ensure `ethical interaction` with human participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Human Conversation\n",
    "- üçé A short dialog between Alice and Mr. Rabbit \n",
    "  ```python\n",
    "  Alice: \"Mr. Rabbit, why are you always in such a rush? Do you ever just... stop to smell the roses?\"\n",
    "  Rabbit: \"Smell the roses? I barely have time to smell the *carrots*! Honestly, I‚Äôm late for everything!\"\n",
    "  Alice: \"Well, at least you‚Äôre never early enough to make a hare-brained decision!\" \n",
    "  Rabbit: üôÇ \"Very funny, Alice. But with these ears, I‚Äôve heard them all!\" \n",
    "  ```\n",
    "- `Conversation Dynamics`\n",
    "   - Human conversation is a complex, joint activity requiring mutual understanding.\n",
    "   - Conversations are structured in `turns`, \n",
    "     - where each speaker contributes sequentially; \n",
    "     - `turn-taking` is essential for natural interaction, as speakers need to know when to start and stop talking.\n",
    "   - Dialogue systems must detect when a user has finished speaking to respond accurately, \n",
    "     - a task known as `endpoint detection`.\n",
    "\n",
    "- `Speech Acts`\n",
    "   - Each utterance in a conversation serves as a specific `speech act`, \n",
    "     - such as answering, requesting, or acknowledging.\n",
    "   - Speech acts are categorized into \n",
    "     - `Constatives` (statements), `Directives` (requests), `Commissives` (promises), and `Acknowledgments` (thanks), \n",
    "     - each reflecting the `speaker's intent`.\n",
    "   - Recognizing speech acts helps dialogue systems interpret user intentions and respond appropriately, \n",
    "     - such as answering questions or confirming details.\n",
    "`\n",
    "- `Grounding`\n",
    "   - *Grounding* is the process of confirming mutual understanding, \n",
    "     - often through `repeating or affirming` statements.\n",
    "     - Examples include saying \"OK\" or repeating key details, \n",
    "       - to establish mutual understanding and build common ground.\n",
    "   - Dialogue systems need grounding mechanisms to ensure they understand and maintain natural conversational flow.\n",
    "\n",
    "- `Dialogue Structure and Subdialogues`\n",
    "   - Conversations often follow structured patterns called `adjacency pairs`, \n",
    "     - like a `question and answer` or a `proposal and acceptance/rejection`.\n",
    "   - `Subdialogues` or side sequences, such as clarifications, \n",
    "     - can temporarily shift focus and require the system to manage interruptions and resume the main conversation.\n",
    "   - `Presequences`, or preliminary questions, set the stage for requests, \n",
    "     - like asking if the system can make reservations before making one.\n",
    "\n",
    "- `Initiative`\n",
    "   - *Initiative* in conversation can be held by one participant or shared; \n",
    "   - `mixed initiative` allows both parties to ask and answer questions, \n",
    "     - typical in human-human dialogue.\n",
    "   - Dialogue systems with full mixed initiative are challenging to build; \n",
    "     - many rely on either `system-initiative` (system-led) or `user-initiative` (user-led) approaches.\n",
    "\n",
    "- `Inference and Implicature`\n",
    "   - *Inference* and *implicature* enable systems to `deduce unstated information` from context, \n",
    "     - such as deducing travel dates based on a meeting time.\n",
    "   - Systems need to `interpret relevance and draw conclusions` beyond literal statements, \n",
    "     - a process crucial for `understanding implicit information` in human conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame-Based Dialogue Systems\n",
    "- `Task-based dialogue` systems assist users with `specific tasks`, such as travel reservations, \n",
    "  - by using `frames‚Äîknowledge structures` with slots for capturing task details, forming a `domain ontology`.\n",
    "- ![Architecture of a dialogue-state system for task-oriented dialogue](./images/chat/diag.png)\n",
    "- The dialogue-state architecture, a common frame-based structure, includes `six components`, with four key components covered here and speech recognition/synthesis introduced later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frames and Slot Filling\n",
    "- Task-based dialogue systems use `frames with slots` to gather necessary details for tasks like booking a hotel or setting an alarm.\n",
    "  - A frame-based system's goal is to `fill these slots` based on user input, \n",
    "    - using `questions` to clarify slot details.\n",
    "    - Simple systems use `pre-written questions`, while advanced systems `generate questions` dynamically.\n",
    "  - Slot fillers are constrained to specific semantic types, such as city or date.\n",
    "  \n",
    "  | **Slot**            | **Type** | **Example Question**                      |\n",
    "  |---------------------|----------|--------------------------------------------|\n",
    "  | ORIGIN CITY         | city     | \"From what city are you leaving?\"          |\n",
    "  | DESTINATION CITY    | city     | \"Where are you going?\"                     |\n",
    "  | DEPARTURE TIME      | time     | \"When would you like to leave?\"            |\n",
    "  | DEPARTURE DATE      | date     | \"What day would you like to leave?\"        |\n",
    "  | ARRIVAL TIME        | time     | \"When do you want to arrive?\"              |\n",
    "  | ARRIVAL DATE        | date     | \"What day would you like to arrive?\"       |  \n",
    "\n",
    "  - `Multiple frames` may be required for `different domains`, \n",
    "    - and the system must identify which frame and slot to use for each input.\n",
    "- `Three key tasks in slot filling` are \n",
    "  - domain classification, \n",
    "  - intent determination, and \n",
    "  - filling slots based on user input.\n",
    "  - üçé ‚ÄúShow me morning flights from Boston to San Francisco on Tuesday‚Äù \n",
    "    - fills slots for origin, destination, and time within the air-travel domain.\n",
    "- `Handwritten rules or machine learning methods` are used for slot-filling, \n",
    "  - with `regular expressions` for simpler tasks like setting an alarm.\n",
    "  - Most modern systems rely on supervised machine learning, \n",
    "    - using labeled examples for domain, intent, and slot-filling.\n",
    "- `BIO tagging` is often employed, where each word is tagged as `beginning (B), inside (I), or outside (O)` a slot label.\n",
    "  - Slot-filling architecture uses a language model encoder, feedforward layer, and softmax output to assign BIO tags.\n",
    "  - ![Slot-filling architecture](./images/chat/fillslot.png)\n",
    "- Synonyms or codes (e.g., ‚ÄúSan Francisco‚Äù to ‚ÄúSFO‚Äù) are normalized using dictionaries, \n",
    "  - with a mix of rules and machine learning used in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Task-Based Dialogue\n",
    "- Task-based systems are evaluated based on \n",
    "  - `task success rate`: correctly completing tasks like booking flights,\n",
    "  - `slot error rate`: percentage of slots correctly filled.\n",
    "\n",
    "- üçé Given sentence `Make an appointment with Chris at 10:30 in Gates 104`, and extracted slot structure:\n",
    "\n",
    "  | **Slot** | **Filler**    |\n",
    "  |----------|---------------|\n",
    "  | PERSON   | Chris         |\n",
    "  | TIME     | 11:30 a.m.    |\n",
    "  | ROOM     | Gates 104     |\n",
    "\n",
    "  - has a slot error rate of 1/3, since the TIME is wrong.\n",
    "\n",
    "- Additional metrics include \n",
    "  - precision, recall, F-score, \n",
    "  - efficiency costs, such as dialogue length in seconds or turns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue Acts and Dialogue State\n",
    "- More complex task-based dialogue systems use `dialogue acts` and `dialogue states` \n",
    "  - to handle confirmations, clarifications, and nuanced interactions with users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogue Acts\n",
    "- Dialogue acts, which extend speech acts, are used to `structure interactions` \n",
    "  - by defining specific functions like `confirming, requesting, or providing information`, \n",
    "  - tailored for particular dialogue tasks.\n",
    "  - üçé [Dialogue acts used by the HIS restaurant recommendation system](https://hal.science/hal-00598186/document)\n",
    "\n",
    "    | **Tag**                  | **Sys** | **User** | **Description**                                               |\n",
    "    |--------------------------|---------|----------|---------------------------------------------------------------|\n",
    "    | HELLO(a = x, b = y, ...) | ‚úî       | ‚úî        | Open a dialogue and give info a = x, b = y, ...               |\n",
    "    | INFORM(a = x, b = y, ...) | ‚úî       | ‚úî        | Give info a = x, b = y, ...                                   |\n",
    "    | REQUEST(a, b = x, ...)   |  ‚úî      | ‚úî        | Request value for a given b = x, ...                          |\n",
    "    | REQALTS(a = x, ...)      |  ‚ùå      |  ‚úî        | Request alternative with a = x, ...                           |\n",
    "    | CONFIRM(a = x, b = y, ...) | ‚úî       | ‚úî        | Explicitly confirm a = x, b = y, ...                          |\n",
    "    | CONFREQ(a = x, ..., d)   | ‚úî       |   ‚ùå       | Implicitly confirm a = x, ... and request value of d          |\n",
    "    | SELECT(a = x, a = y)     | ‚úî       |  ‚ùå        | Implicitly confirm a = x, ... and request value of d          |\n",
    "    | AFFIRM(a = x, b = y, ...) | ‚úî       | ‚úî        | Affirm and give further info a = x, b = y, ...                |\n",
    "    | NEGATE(a = x)            |  ‚ùå       | ‚úî        | Negate and give corrected value a = x                         |\n",
    "    | DENY(a = x)              | ‚ùå       | ‚úî        | Deny that a = x                                               |\n",
    "    | BYE()                    | ‚úî       | ‚úî        | Close a dialogue                                              |\n",
    "\n",
    "- A sample tagset for [the HIS System](https://hal.science/hal-00598186/document) includes \n",
    "  - acts like INFORM, CONFIRM, and REQUEST to handle user needs,\n",
    "  - as shown in a HIS system example where users confirm preferences, inquire about specifics, and close dialogues.\n",
    "\n",
    "    | **Utterance**                                        | **Dialogue Act**                                       |\n",
    "    |------------------------------------------------------|--------------------------------------------------------|\n",
    "    | U: Hi, I am looking for somewhere to eat.            | hello(task = find, type = restaurant)                   |\n",
    "    | S: You are looking for a restaurant. What type of food do you like? | confreq(type = restaurant, food)         |\n",
    "    | U: I‚Äôd like an Italian near the museum.              | inform(food = Italian, near = museum)                   |\n",
    "    | S: Roma is a nice Italian restaurant near the museum. | inform(name = \"Roma\", type = restaurant, food = Italian, near = museum) |\n",
    "    | U: Is it reasonably priced?                          | confirm(pricerange = moderate)                          |\n",
    "    | S: Yes, Roma is in the moderate price range.         | affirm(name = \"Roma\", pricerange = moderate)            |\n",
    "    | U: What is the phone number?                         | request(phone)                                          |\n",
    "    | S: The number of Roma is 385456.                     | inform(name = \"Roma\", phone = \"385456\")                 |\n",
    "    | U: Ok, thank you goodbye.                            | bye()                                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogue State Tracking\n",
    "- The dialogue-state tracker determines the `current state of the frame` and `the most recent user dialogue act`, \n",
    "  - summarizing all user constraints.\n",
    "- Dialogue act detection involves `classifying the user's input sentence` using an encoder and an act classifier, \n",
    "  - with prior dialogue acts improving classification.\n",
    "- Dialogue-act detection and slot-filling tasks are often performed together, \n",
    "  - as dialogue acts constrain slot values.\n",
    "- The state tracker uses slot-filling output or a classifying model to track changes in slot values after each sentence.\n",
    "- Detecting correction acts is essential, as users may rephrase or correct utterances, \n",
    "  - which are harder to recognize due to speech adjustments like `hyperarticulation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogue Policy: Which act to generate\n",
    "- Early frame-based systems followed a simple `dialogue policy`: \n",
    "  - ask questions until all slots are filled, \n",
    "  - then query the database and report back.\n",
    "- A more advanced dialogue policy helps systems decide when to respond, \n",
    "  - ask for clarification, or take other actions, \n",
    "  - guiding the generation of dialogue acts.\n",
    "- Systems often misrecognize words or meaning, \n",
    "  - so they use explicit or implicit confirmation acts to ensure shared understanding with the user.\n",
    "  - Explicit confirmation acts allow users to easily correct misrecognitions, but they can be time-consuming and awkward,\n",
    "    - whereas implicit confirmation is more efficient.\n",
    "- Systems use `ASR (Automatic Speech Recognition) confidence levels` to decide \n",
    "  - when to confirm explicitly, implicitly, or reject based on transcription accuracy, \n",
    "  - with different thresholds for each action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural language generation: Sentence Realization\n",
    "- **Sentence realization** is the process of `generating a user response` after a dialogue act and slots are chosen by the content planner.\n",
    "- The system uses **delexicalization** to generalize training examples, \n",
    "  - replacing specific slot values with generic tokens for flexibility in generating sentences.\n",
    "- üçé [A restaurant recommendation system](https://www.isca-archive.org/interspeech_2017/nayak17_interspeech.html): \n",
    "  - The content planner selects a dialogue act and attributes (e.g., restaurant name, neighborhood, cuisine), \n",
    "  - and the sentence realizer generates different possible sentences based on these inputs.\n",
    "\n",
    "  | Delexicalized sentences |\n",
    "  |---------|\n",
    "  | recommend(restaurant name= Au Midi, neighborhood = midtown, cuisine = french) |\n",
    "  | 1. restaurant name is in neighborhood and serves cuisine food. |\n",
    "  | 2. There is a cuisine restaurant in neighborhood called restaurant name. |\n",
    "\n",
    "- An **encoder-decoder model** is used to map frames (slots and fillers) to delexicalized sentences, \n",
    "  - which are later relexicalized with specific values.\n",
    "  - ![An encoder decoder sentence realizer mapping slots/fillers to English](./images/chat/delex.png)\n",
    "- The **encoder-decoder model** is trained on labeled dialogue corpora like MultiWOZ to improve sentence realization, \n",
    "  - enabling the system to generate varied responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbots\n",
    "- Chatbots evolved from early systems like ELIZA to neural models like ChatGPT, integrating NLP tasks.\n",
    "- Recent neural chatbots focus on functional applications like question answering and machine translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training chatbots\n",
    "- Chatbots are trained on `large language model data`, \n",
    "  - including web sources like Common Crawl, Wikipedia, and books.\n",
    "  - Additional `dialogue datasets`, like [Topical-Chat](https://github.com/alexa/Topical-Chat) and [EMPATHETIC DIALOGUES](https://paperswithcode.com/dataset/empatheticdialogues), \n",
    "    - are often used to train chatbots with real conversations.\n",
    "  - `Social media` data from platforms like Twitter, Reddit, and Weibo is also used, \n",
    "    - with posts treated as conversation starters and comments as replies.\n",
    "  - Datasets from the web are `filtered for toxicity` using toxicity classifiers before being used for training.\n",
    "- Chatbot models are typically trained using a `causal language model architecture (decoder-only)`, \n",
    "  - predicting each word based on previous words in a conversation.\n",
    "  - ![Training a causal (decoder-only) language model for a chatbot.](./images/chat/casual.png)\n",
    "- An alternative approach is to use an `encoder-decoder architecture`, \n",
    "  - where the encoder processes the entire conversation and the decoder generates the next turn.\n",
    "  - ![an encoder-decoder language model for a chatbot](./images/chat/ed.png)\n",
    "- Despite pretraining on dialogue data, \n",
    "  - further f`ine-tuning` is often required to customize the chatbot for specific tasks.\n",
    "  - Fine-tuning stages are essential for improving the chatbot's responses and aligning with desired conversational behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning for Quality and Safety\n",
    "- Dialogue systems are fine-tuned using `labeled data` to improve the quality and safety of responses, \n",
    "  - ensuring sensible and interesting dialogue while `avoiding harmful suggestions`.\n",
    "- Fine-tuning involves training the system with high-quality, safe dialogues, \n",
    "  - often using a `multi-task learning approach` for tasks like answering questions and following instructions.\n",
    "- Additional discriminative data is used to downweight low-quality or harmful responses, \n",
    "  - with `human-labeled ratings` for safety and quality assigned to each system turn.\n",
    "- A language model can classify the quality and safety of responses by \n",
    "  - generating a label (e.g., `SENSIBLE, INTERESTING, UNSAFE`) \n",
    "  - in a two-phase process: `generative and discriminative`.\n",
    "- At inference time, the system generates responses and assigns `safety/quality labels` to filter out unsafe options, \n",
    "  - returning the `highest-ranking safe response` to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning to perform retrieval as part of responding\n",
    "- Modern chatbots, like Sparrow, integrate `retrieval-based` components \n",
    "  - where a fake dialogue participant (e.g., Search Query) is used to query search engines for information.\n",
    "- Chatbot prompts can include special participants (`Search Query and Search Results`) \n",
    "  - to guide the system in generating search queries and handling fact-based questions.\n",
    "- Systems can be fine-tuned to trigger search queries by using labeled data, \n",
    "  - where labelers perform fact checks and create appropriate search queries for incorrect responses.\n",
    "  - The chatbot then uses search results as context to refine its responses, similar to retrieval-based question-answering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Chatbots\n",
    "- Chatbots are evaluated by \n",
    "  - `participants`: who chat with the bot\n",
    "  - or `observers`: who read transcripts.\n",
    "- Evaluations use [Likert scales](https://en.wikipedia.org/wiki/Likert_scale) to rate qualities like engagingness, fluency, and humanness.\n",
    "  - Observer evaluations focus on turn coherence or overall conversation quality.\n",
    "  - The acute-eval metric compares two systems on metrics like engagingness and knowledgability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-üèÉ Practice from HuggingFace NLP\n",
    "  - [Summarization](https://huggingface.co/learn/nlp-course/en/chapter7/5?fw=pt)\n",
    "  - [Training a causal language model from scratch](https://huggingface.co/learn/nlp-course/en/chapter7/5?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
