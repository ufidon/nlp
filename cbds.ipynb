{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ufidon/nlp/blob/main/cbds.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ufidon/nlp/blob/main/cbds.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "**Chatbots & Dialogue Systems**\n",
    "\n",
    "- üìù SALP chapter 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "- `Conversation` is a foundational aspect of language, learned early and used widely, driving the design of `interactive programs` such as \n",
    "  - `frame-based` dialogue systems for `structured tasks` \n",
    "  - `chatbots` for more flexible, `unstructured` conversations\n",
    "  - many modern systems blend both, as seen in tools like Siri and ChatGPT.\n",
    "\n",
    "- Early chatbot ELIZA, designed to simulate a therapist, used `simple pattern-matching and regular expressions`, creating responses that seemed personalized and led users to feel emotionally connected.\n",
    "  - Its responses were crafted based on `specific keywords`, allowing the system to adapt replies to certain words for more engaging interactions, sometimes using `general responses` when no keywords were matched.\n",
    "  - It demonstrated that users could become emotionally involved, often treating the system as a human, which led to behaviors typical of human interactions, like sharing personal issues.\n",
    "\n",
    "- `Emotional attachment` to chatbots raises privacy concerns; \n",
    "  - users tend to disclose private information more freely, increasing risks, especially when the chatbot seems more human-like.\n",
    "  - Privacy and emotional impact require careful consideration when designing and deploying chatbots,\n",
    "    - as they may inadvertently influence users' emotional well-being and cognitive states.\n",
    "- Chatbot usage, especially in `sensitive areas`, may need oversight, such as Institutional Review Board (IRB) approval, to ensure `ethical interaction` with human participants."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Properties of Human Conversation\n",
    "- üçé A short dialog between Alice and Mr. Rabbit \n",
    "  ```python\n",
    "  Alice: \"Mr. Rabbit, why are you always in such a rush? Do you ever just... stop to smell the roses?\"\n",
    "  Rabbit: \"Smell the roses? I barely have time to smell the *carrots*! Honestly, I‚Äôm late for everything!\"\n",
    "  Alice: \"Well, at least you‚Äôre never early enough to make a hare-brained decision!\" \n",
    "  Rabbit: üôÇ \"Very funny, Alice. But with these ears, I‚Äôve heard them all!\" \n",
    "  ```\n",
    "- `Conversation Dynamics`\n",
    "   - Human conversation is a complex, joint activity requiring mutual understanding.\n",
    "   - Conversations are structured in `turns`, \n",
    "     - where each speaker contributes sequentially; \n",
    "     - `turn-taking` is essential for natural interaction, as speakers need to know when to start and stop talking.\n",
    "   - Dialogue systems must detect when a user has finished speaking to respond accurately, \n",
    "     - a task known as `endpoint detection`.\n",
    "\n",
    "- `Speech Acts`\n",
    "   - Each utterance in a conversation serves as a specific `speech act`, \n",
    "     - such as answering, requesting, or acknowledging.\n",
    "   - Speech acts are categorized into \n",
    "     - `Constatives` (statements), `Directives` (requests), `Commissives` (promises), and `Acknowledgments` (thanks), \n",
    "     - each reflecting the `speaker's intent`.\n",
    "   - Recognizing speech acts helps dialogue systems interpret user intentions and respond appropriately, \n",
    "     - such as answering questions or confirming details.\n",
    "`\n",
    "- `Grounding`\n",
    "   - *Grounding* is the process of confirming mutual understanding, \n",
    "     - often through `repeating or affirming` statements.\n",
    "     - Examples include saying \"OK\" or repeating key details, \n",
    "       - to establish mutual understanding and build common ground.\n",
    "   - Dialogue systems need grounding mechanisms to ensure they understand and maintain natural conversational flow.\n",
    "\n",
    "- `Dialogue Structure and Subdialogues`\n",
    "   - Conversations often follow structured patterns called `adjacency pairs`, \n",
    "     - like a `question and answer` or a `proposal and acceptance/rejection`.\n",
    "   - `Subdialogues` or side sequences, such as clarifications, \n",
    "     - can temporarily shift focus and require the system to manage interruptions and resume the main conversation.\n",
    "   - `Presequences`, or preliminary questions, set the stage for requests, \n",
    "     - like asking if the system can make reservations before making one.\n",
    "\n",
    "- `Initiative`\n",
    "   - *Initiative* in conversation can be held by one participant or shared; \n",
    "   - `mixed initiative` allows both parties to ask and answer questions, \n",
    "     - typical in human-human dialogue.\n",
    "   - Dialogue systems with full mixed initiative are challenging to build; \n",
    "     - many rely on either `system-initiative` (system-led) or `user-initiative` (user-led) approaches.\n",
    "\n",
    "- `Inference and Implicature`\n",
    "   - *Inference* and *implicature* enable systems to `deduce unstated information` from context, \n",
    "     - such as deducing travel dates based on a meeting time.\n",
    "   - Systems need to `interpret relevance and draw conclusions` beyond literal statements, \n",
    "     - a process crucial for `understanding implicit information` in human conversation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Frame-Based Dialogue Systems\n",
    "- `Task-based dialogue` systems assist users with `specific tasks`, such as travel reservations, \n",
    "  - by using `frames‚Äîknowledge structures` with slots for capturing task details, forming a `domain ontology`.\n",
    "- ![Architecture of a dialogue-state system for task-oriented dialogue](./images/chat/diag.png)\n",
    "- The dialogue-state architecture, a common frame-based structure, includes `six components`, with four key components covered here and speech recognition/synthesis introduced later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Frames and Slot Filling\n",
    "- Task-based dialogue systems use `frames with slots` to gather necessary details for tasks like booking a hotel or setting an alarm.\n",
    "  - A frame-based system's goal is to `fill these slots` based on user input, \n",
    "    - using `questions` to clarify slot details.\n",
    "    - Simple systems use `pre-written questions`, while advanced systems `generate questions` dynamically.\n",
    "  - Slot fillers are constrained to specific semantic types, such as city or date.\n",
    "  \n",
    "  | **Slot**            | **Type** | **Example Question**                      |\n",
    "  |---------------------|----------|--------------------------------------------|\n",
    "  | ORIGIN CITY         | city     | \"From what city are you leaving?\"          |\n",
    "  | DESTINATION CITY    | city     | \"Where are you going?\"                     |\n",
    "  | DEPARTURE TIME      | time     | \"When would you like to leave?\"            |\n",
    "  | DEPARTURE DATE      | date     | \"What day would you like to leave?\"        |\n",
    "  | ARRIVAL TIME        | time     | \"When do you want to arrive?\"              |\n",
    "  | ARRIVAL DATE        | date     | \"What day would you like to arrive?\"       |  \n",
    "\n",
    "  - `Multiple frames` may be required for `different domains`, \n",
    "    - and the system must identify which frame and slot to use for each input.\n",
    "- `Three key tasks in slot filling` are \n",
    "  - domain classification, \n",
    "  - intent determination, and \n",
    "  - filling slots based on user input.\n",
    "  - üçé ‚ÄúShow me morning flights from Boston to San Francisco on Tuesday‚Äù \n",
    "    - fills slots for origin, destination, and time within the air-travel domain.\n",
    "- `Handwritten rules or machine learning methods` are used for slot-filling, \n",
    "  - with `regular expressions` for simpler tasks like setting an alarm.\n",
    "  - Most modern systems rely on supervised machine learning, \n",
    "    - using labeled examples for domain, intent, and slot-filling.\n",
    "- `BIO tagging` is often employed, where each word is tagged as `beginning (B), inside (I), or outside (O)` a slot label.\n",
    "  - Slot-filling architecture uses a language model encoder, feedforward layer, and softmax output to assign BIO tags.\n",
    "  - ![Slot-filling architecture](./images/chat/fillslot.png)\n",
    "- Synonyms or codes (e.g., ‚ÄúSan Francisco‚Äù to ‚ÄúSFO‚Äù) are normalized using dictionaries, \n",
    "  - with a mix of rules and machine learning used in practical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Task-Based Dialogue\n",
    "- Task-based systems are evaluated based on \n",
    "  - `task success rate`: correctly completing tasks like booking flights,\n",
    "  - `slot error rate`: percentage of slots correctly filled.\n",
    "\n",
    "- üçé Given sentence `Make an appointment with Chris at 10:30 in Gates 104`, and extracted slot structure:\n",
    "\n",
    "  | **Slot** | **Filler**    |\n",
    "  |----------|---------------|\n",
    "  | PERSON   | Chris         |\n",
    "  | TIME     | 11:30 a.m.    |\n",
    "  | ROOM     | Gates 104     |\n",
    "\n",
    "  - has a slot error rate of 1/3, since the TIME is wrong.\n",
    "\n",
    "- Additional metrics include \n",
    "  - precision, recall, F-score, \n",
    "  - efficiency costs, such as dialogue length in seconds or turns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue Acts and Dialogue State\n",
    "- More complex task-based dialogue systems use `dialogue acts` and `dialogue states` \n",
    "  - to handle confirmations, clarifications, and nuanced interactions with users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogue Acts\n",
    "- Dialogue acts, which extend speech acts, are used to `structure interactions` \n",
    "  - by defining specific functions like `confirming, requesting, or providing information`, \n",
    "  - tailored for particular dialogue tasks.\n",
    "  - üçé [Dialogue acts used by the HIS restaurant recommendation system](https://hal.science/hal-00598186/document)\n",
    "\n",
    "    | **Tag**                  | **Sys** | **User** | **Description**                                               |\n",
    "    |--------------------------|---------|----------|---------------------------------------------------------------|\n",
    "    | HELLO(a = x, b = y, ...) | ‚úî       | ‚úî        | Open a dialogue and give info a = x, b = y, ...               |\n",
    "    | INFORM(a = x, b = y, ...) | ‚úî       | ‚úî        | Give info a = x, b = y, ...                                   |\n",
    "    | REQUEST(a, b = x, ...)   |  ‚úî      | ‚úî        | Request value for a given b = x, ...                          |\n",
    "    | REQALTS(a = x, ...)      |  ‚ùå      |  ‚úî        | Request alternative with a = x, ...                           |\n",
    "    | CONFIRM(a = x, b = y, ...) | ‚úî       | ‚úî        | Explicitly confirm a = x, b = y, ...                          |\n",
    "    | CONFREQ(a = x, ..., d)   | ‚úî       |   ‚ùå       | Implicitly confirm a = x, ... and request value of d          |\n",
    "    | SELECT(a = x, a = y)     | ‚úî       |  ‚ùå        | Implicitly confirm a = x, ... and request value of d          |\n",
    "    | AFFIRM(a = x, b = y, ...) | ‚úî       | ‚úî        | Affirm and give further info a = x, b = y, ...                |\n",
    "    | NEGATE(a = x)            |  ‚ùå       | ‚úî        | Negate and give corrected value a = x                         |\n",
    "    | DENY(a = x)              | ‚ùå       | ‚úî        | Deny that a = x                                               |\n",
    "    | BYE()                    | ‚úî       | ‚úî        | Close a dialogue                                              |\n",
    "\n",
    "- A sample tagset for [the HIS System](https://hal.science/hal-00598186/document) includes \n",
    "  - acts like INFORM, CONFIRM, and REQUEST to handle user needs,\n",
    "  - as shown in a HIS system example where users confirm preferences, inquire about specifics, and close dialogues.\n",
    "\n",
    "    | **Utterance**                                        | **Dialogue Act**                                       |\n",
    "    |------------------------------------------------------|--------------------------------------------------------|\n",
    "    | U: Hi, I am looking for somewhere to eat.            | hello(task = find, type = restaurant)                   |\n",
    "    | S: You are looking for a restaurant. What type of food do you like? | confreq(type = restaurant, food)         |\n",
    "    | U: I‚Äôd like an Italian near the museum.              | inform(food = Italian, near = museum)                   |\n",
    "    | S: Roma is a nice Italian restaurant near the museum. | inform(name = \"Roma\", type = restaurant, food = Italian, near = museum) |\n",
    "    | U: Is it reasonably priced?                          | confirm(pricerange = moderate)                          |\n",
    "    | S: Yes, Roma is in the moderate price range.         | affirm(name = \"Roma\", pricerange = moderate)            |\n",
    "    | U: What is the phone number?                         | request(phone)                                          |\n",
    "    | S: The number of Roma is 385456.                     | inform(name = \"Roma\", phone = \"385456\")                 |\n",
    "    | U: Ok, thank you goodbye.                            | bye()                                                   |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogue State Tracking\n",
    "- The dialogue-state tracker determines the `current state of the frame` and `the most recent user dialogue act`, \n",
    "  - summarizing all user constraints.\n",
    "- Dialogue act detection involves `classifying the user's input sentence` using an encoder and an act classifier, \n",
    "  - with prior dialogue acts improving classification.\n",
    "- Dialogue-act detection and slot-filling tasks are often performed together, \n",
    "  - as dialogue acts constrain slot values.\n",
    "- The state tracker uses slot-filling output or a classifying model to track changes in slot values after each sentence.\n",
    "- Detecting correction acts is essential, as users may rephrase or correct utterances, \n",
    "  - which are harder to recognize due to speech adjustments like `hyperarticulation`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dialogue Policy: Which act to generate\n",
    "- Early frame-based systems followed a simple `dialogue policy`: \n",
    "  - ask questions until all slots are filled, \n",
    "  - then query the database and report back.\n",
    "- A more advanced dialogue policy helps systems decide when to respond, \n",
    "  - ask for clarification, or take other actions, \n",
    "  - guiding the generation of dialogue acts.\n",
    "- Systems often misrecognize words or meaning, \n",
    "  - so they use explicit or implicit confirmation acts to ensure shared understanding with the user.\n",
    "  - Explicit confirmation acts allow users to easily correct misrecognitions, but they can be time-consuming and awkward,\n",
    "    - whereas implicit confirmation is more efficient.\n",
    "- Systems use `ASR (Automatic Speech Recognition) confidence levels` to decide \n",
    "  - when to confirm explicitly, implicitly, or reject based on transcription accuracy, \n",
    "  - with different thresholds for each action."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural language generation: Sentence Realization\n",
    "- **Sentence realization** is the process of `generating a user response` after a dialogue act and slots are chosen by the content planner.\n",
    "- The system uses **delexicalization** to generalize training examples, \n",
    "  - replacing specific slot values with generic tokens for flexibility in generating sentences.\n",
    "- üçé [A restaurant recommendation system](https://www.isca-archive.org/interspeech_2017/nayak17_interspeech.html): \n",
    "  - The content planner selects a dialogue act and attributes (e.g., restaurant name, neighborhood, cuisine), \n",
    "  - and the sentence realizer generates different possible sentences based on these inputs.\n",
    "\n",
    "  | Delexicalized sentences |\n",
    "  |---------|\n",
    "  | recommend(restaurant name= Au Midi, neighborhood = midtown, cuisine = french) |\n",
    "  | 1. restaurant name is in neighborhood and serves cuisine food. |\n",
    "  | 2. There is a cuisine restaurant in neighborhood called restaurant name. |\n",
    "\n",
    "- An **encoder-decoder model** is used to map frames (slots and fillers) to delexicalized sentences, \n",
    "  - which are later relexicalized with specific values.\n",
    "  - ![An encoder decoder sentence realizer mapping slots/fillers to English](./images/chat/delex.png)\n",
    "- The **encoder-decoder model** is trained on labeled dialogue corpora like MultiWOZ to improve sentence realization, \n",
    "  - enabling the system to generate varied responses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbots\n",
    "- Chatbots evolved from early systems like ELIZA to neural models like ChatGPT, integrating NLP tasks.\n",
    "- Recent neural chatbots focus on functional applications like question answering and machine translation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training chatbots\n",
    "- Chatbots are trained on `large language model data`, \n",
    "  - including web sources like Common Crawl, Wikipedia, and books.\n",
    "  - Additional `dialogue datasets`, like [Topical-Chat](https://github.com/alexa/Topical-Chat) and [EMPATHETIC DIALOGUES](https://paperswithcode.com/dataset/empatheticdialogues), \n",
    "    - are often used to train chatbots with real conversations.\n",
    "  - `Social media` data from platforms like Twitter, Reddit, and Weibo is also used, \n",
    "    - with posts treated as conversation starters and comments as replies.\n",
    "  - Datasets from the web are `filtered for toxicity` using toxicity classifiers before being used for training.\n",
    "- Chatbot models are typically trained using a `causal language model architecture (decoder-only)`, \n",
    "  - predicting each word based on previous words in a conversation.\n",
    "  - ![Training a causal (decoder-only) language model for a chatbot.](./images/chat/casual.png)\n",
    "- An alternative approach is to use an `encoder-decoder architecture`, \n",
    "  - where the encoder processes the entire conversation and the decoder generates the next turn.\n",
    "  - ![an encoder-decoder language model for a chatbot](./images/chat/ed.png)\n",
    "- Despite pretraining on dialogue data, \n",
    "  - further f`ine-tuning` is often required to customize the chatbot for specific tasks.\n",
    "  - Fine-tuning stages are essential for improving the chatbot's responses and aligning with desired conversational behaviors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine Tuning for Quality and Safety\n",
    "- Dialogue systems are fine-tuned using `labeled data` to improve the quality and safety of responses, \n",
    "  - ensuring sensible and interesting dialogue while `avoiding harmful suggestions`.\n",
    "- Fine-tuning involves training the system with high-quality, safe dialogues, \n",
    "  - often using a `multi-task learning approach` for tasks like answering questions and following instructions.\n",
    "- Additional discriminative data is used to downweight low-quality or harmful responses, \n",
    "  - with `human-labeled ratings` for safety and quality assigned to each system turn.\n",
    "- A language model can classify the quality and safety of responses by \n",
    "  - generating a label (e.g., `SENSIBLE, INTERESTING, UNSAFE`) \n",
    "  - in a two-phase process: `generative and discriminative`.\n",
    "- At inference time, the system generates responses and assigns `safety/quality labels` to filter out unsafe options, \n",
    "  - returning the `highest-ranking safe response` to the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning to perform retrieval as part of responding\n",
    "- Modern chatbots, like Sparrow, integrate `retrieval-based` components \n",
    "  - where a fake dialogue participant (e.g., Search Query) is used to query search engines for information.\n",
    "- Chatbot prompts can include special participants (`Search Query and Search Results`) \n",
    "  - to guide the system in generating search queries and handling fact-based questions.\n",
    "- Systems can be fine-tuned to trigger search queries by using labeled data, \n",
    "  - where labelers perform fact checks and create appropriate search queries for incorrect responses.\n",
    "  - The chatbot then uses search results as context to refine its responses, similar to retrieval-based question-answering methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating Chatbots\n",
    "- Chatbots are evaluated by \n",
    "  - `participants`: who chat with the bot\n",
    "  - or `observers`: who read transcripts.\n",
    "- Evaluations use [Likert scales](https://en.wikipedia.org/wiki/Likert_scale) to rate qualities like engagingness, fluency, and humanness.\n",
    "  - Observer evaluations focus on turn coherence or overall conversation quality.\n",
    "  - The acute-eval metric compares two systems on metrics like engagingness and knowledgability."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dialogue System Design\n",
    "- Dialogue systems, especially task-oriented ones, are closely linked to `Human-Computer Interaction (HCI)` and follow `user-centered` design.\n",
    "- Designers study users and tasks by \n",
    "  - interviewing users, \n",
    "  - examining similar systems, \n",
    "  - and analyzing human-human dialogues.\n",
    "- [Wizard-of-Oz](https://en.wikipedia.org/wiki/Wizard_of_Oz_experiment) systems allow simulation of dialogue interactions with a human `wizard` controlling responses, \n",
    "  - enabling early testing of system architecture and interface.\n",
    "- Wizard systems reveal design issues but may not fully replicate real system limitations,\n",
    "  - providing an initial understanding of dialogue dynamics.\n",
    "- Iterative user testing refines design to align with user behavior, \n",
    "  - while `value-sensitive design principles` consider the potential impact on the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ethical Issues in Dialogue System Design\n",
    "- `Ethical concerns` in AI and dialogue systems date back to early discussions, \n",
    "  - as seen in Mary Shelley‚Äôs *Frankenstein*, \n",
    "  - about the risks of creating agents without considering human impact.\n",
    "- `Safety` is crucial, especially for dialogue systems used in medical or emergency situations;\n",
    "  - incorrect advice can endanger users.\n",
    "- Dialogue systems may perpetuate harmful stereotypes, as seen with `Microsoft‚Äôs Tay`, \n",
    "  - which `learned offensive behavior` from biased user input.\n",
    "- Training data often contain `toxic language`, which AI systems can replicate and amplify,\n",
    "  - leading to representational harms for certain groups.\n",
    "- `Privacy` is a major issue, as dialogue systems frequently overhear personal information and users may disclose more to human-like systems.\n",
    "- `Gender bias` is prevalent, with many chatbots assigned female names, \n",
    "  - reinforcing subservient stereotypes and inadequately addressing harassment.\n",
    "- Addressing abuse and toxicity in dialogue systems is vital, \n",
    "  - with methods including toxicity detection and value-sensitive design practices.\n",
    "- Researchers prioritize participant consent and ethical reviews, \n",
    "  - often consulting `Institutional Review Boards (IRBs)` to protect human subjects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-üèÉ Practice from HuggingFace NLP\n",
    "  - [Summarization](https://huggingface.co/learn/nlp-course/en/chapter7/5?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Preparing a multilingual corpus\n",
    "# https://huggingface.co/datasets/defunct-datasets/amazon_reviews_multi\n",
    "from datasets import load_dataset, DatasetDict\n",
    "\n",
    "!curl -L -o ./archive.zip https://www.kaggle.com/api/v1/datasets/download/mexwell/amazon-reviews-multi\n",
    "!unzip archive.zip\n",
    "\n",
    "data_files={\n",
    "    'train':'train.csv',\n",
    "    'validation':'validation.csv',\n",
    "    'test':'test.csv'}\n",
    "\n",
    "dataset = load_dataset('csv',data_files=data_files)\n",
    "\n",
    "partitioned_datasets = DatasetDict()\n",
    "\n",
    "# Get unique languages in the train, validation, and test sets\n",
    "languages = set(dataset['train'].unique('language'))\n",
    "languages.update(dataset['validation'].unique('language'))\n",
    "languages.update(dataset['test'].unique('language'))\n",
    "\n",
    "# Partition the dataset based on each unique language\n",
    "for lang in languages:\n",
    "    partitioned_datasets[lang] = DatasetDict({\n",
    "        \"train\": dataset[\"train\"].filter(lambda x: x[\"language\"] == lang),\n",
    "        \"validation\": dataset[\"validation\"].filter(lambda x: x[\"language\"] == lang),\n",
    "        \"test\": dataset[\"test\"].filter(lambda x: x[\"language\"] == lang)\n",
    "    })\n",
    "\n",
    "print(partitioned_datasets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_dataset = partitioned_datasets['zh'] # Chinese\n",
    "chinese_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_dataset = partitioned_datasets['en'] # English\n",
    "english_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 show samples\n",
    "def show_samples(dataset, num_samples=3, seed=42):\n",
    "    sample = dataset[\"train\"].shuffle(seed=seed).select(range(num_samples))\n",
    "    for example in sample:\n",
    "        print(f\"\\n'>> Title: {example['review_title']}'\")\n",
    "        print(f\"'>> Review: {example['review_body']}'\")\n",
    "\n",
    "\n",
    "show_samples(english_dataset)\n",
    "show_samples(chinese_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 find an interesting domain of products\n",
    "english_dataset.set_format(\"pandas\")\n",
    "english_df = english_dataset[\"train\"][:]\n",
    "# Show counts for top 20 products\n",
    "english_df[\"product_category\"].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_dataset.set_format(\"pandas\")\n",
    "chinese_df = chinese_dataset[\"train\"][:]\n",
    "# Show counts for top 20 products\n",
    "chinese_df[\"product_category\"].value_counts()[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 choose books\n",
    "def filter_books(example):\n",
    "    return (\n",
    "        example[\"product_category\"] == \"book\"\n",
    "        or example[\"product_category\"] == \"digital_ebook_purchase\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# switch the format from \"pandas\" back to \"arrow\":\n",
    "english_dataset.reset_format()\n",
    "chinese_dataset.reset_format()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chinese_books = chinese_dataset.filter(filter_books)\n",
    "english_books = english_dataset.filter(filter_books)\n",
    "# the reviews are not strictly about books :(\n",
    "show_samples(chinese_books)\n",
    "show_samples(english_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 combine them into a bilingual dataset\n",
    "from datasets import concatenate_datasets, DatasetDict\n",
    "\n",
    "books_dataset = DatasetDict()\n",
    "\n",
    "for split in english_books.keys():\n",
    "    books_dataset[split] = concatenate_datasets(\n",
    "        [english_books[split], chinese_books[split]]\n",
    "    )\n",
    "    books_dataset[split] = books_dataset[split].shuffle(seed=42)\n",
    "\n",
    "# Peek at a few examples\n",
    "show_samples(books_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Models for text summarization\n",
    "# [mT5](https://huggingface.co/google/mt5-base) \n",
    "# [mBART-50](https://huggingface.co/facebook/mbart-large-50)\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"google/mt5-small\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unigram is especially useful for multilingual corpora\n",
    "# since it allows SentencePiece to be agnostic about accents, \n",
    "# punctuation, and the fact that many languages, \n",
    "# like Chinese, do not have whitespace characters.\n",
    "zinputs = tokenizer(\"ËøôÊú¨„ÄäË•øÊ∏∏ËÆ∞„ÄãÂ•ΩÊúâË∂£!\")\n",
    "zinputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(zinputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "einputs = tokenizer(\"I loved reading the Hunger Games!\")\n",
    "einputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.convert_ids_to_tokens(einputs.input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Preprocessing the data\n",
    "# `text_target` argument that allows you to \n",
    "# tokenize the labels in parallel to the inputs.\n",
    "\n",
    "max_input_length = 512\n",
    "max_target_length = 30\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    model_inputs = tokenizer(\n",
    "        examples[\"review_body\"],\n",
    "        max_length=max_input_length,\n",
    "        truncation=True,\n",
    "    )\n",
    "    labels = tokenizer(\n",
    "        examples[\"review_title\"], max_length=max_target_length, truncation=True\n",
    "    )\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_datasets = books_dataset.map(preprocess_function, batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Metrics for text summarization\n",
    "generated_summary = \"I absolutely loved reading the Hunger Games\"\n",
    "reference_summary = \"I loved reading the Hunger Games\"\n",
    "\n",
    "!pip install rouge_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "rouge_score = evaluate.load(\"rouge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate all the metrics at once:\n",
    "scores = rouge_score.compute(\n",
    "    predictions=[generated_summary], references=[reference_summary]\n",
    ")\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Creating a strong baseline\n",
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "nltk.download(\"punkt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "def three_sentence_summary(text):\n",
    "    return \"\\n\".join(sent_tokenize(text)[:3])\n",
    "\n",
    "\n",
    "print(three_sentence_summary(books_dataset[\"train\"][1][\"review_body\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes the ROUGE scores for the baseline:\n",
    "def evaluate_baseline(dataset, metric):\n",
    "    summaries = [three_sentence_summary(text) for text in dataset[\"review_body\"]]\n",
    "    return metric.compute(predictions=summaries, references=dataset[\"review_title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "score = evaluate_baseline(books_dataset[\"validation\"], rouge_score)\n",
    "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
    "rouge_dict = dict((rn, round(score[rn] * 100, 2)) for rn in rouge_names)\n",
    "rouge_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Fine-tuning mT5 with the Trainer API\n",
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "batch_size = 8\n",
    "num_train_epochs = 8\n",
    "# Show the training loss with every epoch\n",
    "logging_steps = len(tokenized_datasets[\"train\"]) // batch_size\n",
    "model_name = model_checkpoint.split(\"/\")[-1]\n",
    "\n",
    "args = Seq2SeqTrainingArguments(\n",
    "    output_dir=f\"./\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5.6e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    weight_decay=0.01,\n",
    "    save_total_limit=3,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    predict_with_generate=True,\n",
    "    logging_steps=logging_steps,\n",
    "    push_to_hub=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    # Decode generated summaries into text\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    # Decode reference summaries into text\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    # ROUGE expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    # Compute ROUGE scores\n",
    "    result = rouge_score.compute(\n",
    "        predictions=decoded_preds, references=decoded_labels, use_stemmer=True\n",
    "    )\n",
    "    # Extract the median scores\n",
    "    result = {key: value * 100 for key, value in result.items()}\n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Fine-tuning mT5 with ü§ó Accelerate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. Preparing everything for training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Training loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Using your fine-tuned model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-üèÉ Practice from HuggingFace NLP\n",
    "  - [Training a causal language model from scratch](https://huggingface.co/learn/nlp-course/en/chapter7/5?fw=pt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
