{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table align=\"left\">\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/ufidon/nlp/blob/main/01.btp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://kaggle.com/kernels/welcome?src=https://github.com/ufidon/nlp/blob/main/01.btp.ipynb\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" /></a>\n",
    "  </td>\n",
    "</table>\n",
    "<br>\n",
    "\n",
    "**Basic Text Processing**\n",
    "---\n",
    "üìù SALP chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçé An Intriguing Example\n",
    "\n",
    "How do we read and comprehend the text below?\n",
    "- parse sentences, words\n",
    "- search for patterns\n",
    "- recognize name entities\n",
    "- find the meaning of words in their context\n",
    "- feel the sentiment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "John Smith, 123 Main St, Anytown USA 12345\n",
    "Phone: (555) 123-4567\n",
    "Email: [john.smith@example.com](mailto:john.smith@example.com)\n",
    "Occupation: Software Engineer\n",
    "\n",
    "Jane Doe, 456 Elm St, Othertown USA 67890\n",
    "Phone: 1-800-789-0123\n",
    "Email: janedoe@gmail.com\n",
    "Occupation: Marketing Manager\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the following information from this text:\n",
    "\n",
    "* Names (first and last)\n",
    "* Addresses\n",
    "* Phone numbers\n",
    "* Email addresses\n",
    "* Occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names:\n",
      "John Smith\n",
      "Main St\n",
      "Anytown USA\n",
      "Software Engineer\n",
      "Jane Doe\n",
      "Elm St\n",
      "Othertown USA\n",
      "Marketing Manager\n",
      "\n",
      "Addresses:\n",
      "123 Main St, Anytown USA 12345\n",
      "456 Elm St, Othertown USA 67890\n",
      "\n",
      "Phone Numbers:\n",
      "(555) 123-4567\n",
      "0-789-0123\n",
      "\n",
      "Email Addresses:\n",
      "john.smith@example.com\n",
      "john.smith@example.com\n",
      "janedoe@gmail.com\n",
      "\n",
      "Occupations:\n",
      "Software Engineer\n",
      "Marketing Manager\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define regex patterns for each piece of information\n",
    "name_pattern = r\"[A-Za-z]+ [A-Za-z]+\"\n",
    "address_pattern = r\"\\d+ [A-Za-z]+ St, [A-Za-z]+ USA \\d{5}\"\n",
    "phone_pattern = r\"\\(\\d{3}\\) \\d{3}-\\d{4}|\\d-\\d{3}-\\d{4}\"\n",
    "email_pattern = r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\"\n",
    "occupation_pattern = r\"Software Engineer|Marketing Manager\"\n",
    "\n",
    "# Use regex to find all occurrences of each pattern\n",
    "names = re.findall(name_pattern, text)\n",
    "addresses = re.findall(address_pattern, text)\n",
    "phones = re.findall(phone_pattern, text)\n",
    "emails = re.findall(email_pattern, text)\n",
    "occupations = re.findall(occupation_pattern, text)\n",
    "\n",
    "# Print the extracted information\n",
    "print(\"Names:\")\n",
    "for name in names:\n",
    "    print(name)\n",
    "\n",
    "print(\"\\nAddresses:\")\n",
    "for address in addresses:\n",
    "    print(address)\n",
    "\n",
    "print(\"\\nPhone Numbers:\")\n",
    "for phone in phones:\n",
    "    print(phone)\n",
    "\n",
    "print(\"\\nEmail Addresses:\")\n",
    "for email in emails:\n",
    "    print(email)\n",
    "\n",
    "print(\"\\nOccupations:\")\n",
    "for occupation in occupations:\n",
    "    print(occupation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regex features used:\n",
    "\n",
    "* Character classes (`[A-Za-z]+`, `\\d+`)\n",
    "* Word boundaries (`\\b`)\n",
    "* Groups (`(\\d{3})`)\n",
    "* Alternation (`|`)\n",
    "* Quantifiers (`*`, `+`, `{5}`)\n",
    "* Anchors (`^`, `$`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Regular Expressions\n",
    "* Regular expressions (regex) are a powerful tool for matching patterns in text data.\n",
    "* In NLP, regex is used for tasks such as:\n",
    "\t+ Text preprocessing\n",
    "\t+ Information extraction\n",
    "\t+ Sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "* **Pattern**: A regular expression is a pattern that matches one or more strings of text.\n",
    "* **Literal characters**: Characters that match themselves (e.g. `a` matches the letter \"a\").\n",
    "* **Metacharacters**: Special characters that have special meanings (e.g. `.` matches any single \n",
    "character).\n",
    "* **Escaping**: Using a backslash (`\\`) to treat metacharacters as literal characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Regex Patterns\n",
    "* **Matching a word**: `\\bword\\b` matches the whole word \"word\".\n",
    "\t+ Example: `import re; print(re.search(r'\\bhello\\b', 'hello world'))`\n",
    "* **Matching a digit**: `\\d` matches any single digit.\n",
    "\t+ Example: `import re; print(re.search(r'\\d', 'abc123def'))`\n",
    "* **Matching whitespace**: `\\s` matches any whitespace character (space, tab, newline).\n",
    "\t+ Example: `import re; print(re.search(r'\\s', 'hello world'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Classes\n",
    "* **Character class**: A set of characters enclosed in square brackets (`[]`).\n",
    "* **Matching a single character from the class**: `[abc]` matches any one of \"a\", \"b\", or \"c\".\n",
    "\t+ Example: `import re; print(re.search(r'[abc]', 'hello'))`\n",
    "* **Negating a character class**: `[^abc]` matches any single character that is not \"a\", \"b\", or \"c\".\n",
    "\t+ Example: `import re; print(re.search(r'[^abc]', 'hello'))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifiers\n",
    "* **Quantifier**: A metacharacter that specifies the number of times a pattern should be matched.\n",
    "* **Matching zero or more occurrences**: `*` matches any number (including zero) of the preceding \n",
    "element.\n",
    "\t+ Example: `import re; print(re.search(r'ab*', 'a'))`\n",
    "* **Matching one or more occurrences**: `+` matches one or more of the preceding element.\n",
    "\t+ Example: `import re; print(re.search(r'ab+', 'ab'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups and Capturing\n",
    "* **Group**: A set of characters enclosed in parentheses (`()`).\n",
    "* **Capturing a group**: `(\\w+)` captures one or more word characters as a group.\n",
    "\t+ Example: `import re; print(re.search(r'(\\w+)', 'hello world'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchors\n",
    "* **Anchor**: A metacharacter that specifies the position of a pattern in a string.\n",
    "* **Matching the start of a string**: `^` matches the start of a string.\n",
    "\t+ Example: `import re; print(re.search(r'^hello', 'hello world'))`\n",
    "* **Matching the end of a string**: `$` matches the end of a string.\n",
    "\t+ Example: `import re; print(re.search(r'world$', 'hello world'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy vs. Lazy Matching\n",
    "* **Greedy matching**: Matches as many characters as possible (default behavior).\n",
    "* **Lazy matching**: Matches as few characters as possible (`?` quantifier).\n",
    "\t+ Example: `import re; print(re.search(r'a.*?b', 'a hello b'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Regex in NLP\n",
    "* **Preprocessing text data**: Use regex to remove punctuation, convert to lowercase, etc.\n",
    "* **Extracting information**: Use regex to extract specific patterns from text data (e.g. phone \n",
    "numbers, email addresses).\n",
    "* **Sentiment analysis**: Use regex to extract sentiment-bearing phrases from text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîó [re ‚Äî Regular expression operations](https://docs.python.org/3/library/re.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçé Example\n",
    "Text Analysis with NLTK:\n",
    "\n",
    "* Tokenize the text into individual words and sentences\n",
    "* Perform stemming on the tokens (i.e., reduce words to their base form)\n",
    "* Identify named entities in the text (e.g., people, places, organizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package words to /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker_tab to\n",
      "[nltk_data]     /home/qingshan/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker_tab is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Tokens:\n",
      "John\n",
      "Smith\n",
      ",\n",
      "123\n",
      "Main\n",
      "St\n",
      ",\n",
      "Anytown\n",
      "USA\n",
      "12345\n",
      "Phone\n",
      ":\n",
      "(\n",
      "555\n",
      ")\n",
      "123-4567\n",
      "Email\n",
      ":\n",
      "[\n",
      "john.smith\n",
      "@\n",
      "example.com\n",
      "]\n",
      "(\n",
      "mailto\n",
      ":\n",
      "john.smith\n",
      "@\n",
      "example.com\n",
      ")\n",
      "Occupation\n",
      ":\n",
      "Software\n",
      "Engineer\n",
      "Jane\n",
      "Doe\n",
      ",\n",
      "456\n",
      "Elm\n",
      "St\n",
      ",\n",
      "Othertown\n",
      "USA\n",
      "67890\n",
      "Phone\n",
      ":\n",
      "1-800-789-0123\n",
      "Email\n",
      ":\n",
      "janedoe\n",
      "@\n",
      "gmail.com\n",
      "Occupation\n",
      ":\n",
      "Marketing\n",
      "Manager\n",
      "\n",
      "Sentence Tokens:\n",
      "\n",
      "John Smith, 123 Main St, Anytown USA 12345\n",
      "Phone: (555) 123-4567\n",
      "Email: [john.smith@example.com](mailto:john.smith@example.com)\n",
      "Occupation: Software Engineer\n",
      "\n",
      "Jane Doe, 456 Elm St, Othertown USA 67890\n",
      "Phone: 1-800-789-0123\n",
      "Email: janedoe@gmail.com\n",
      "Occupation: Marketing Manager\n",
      "\n",
      "Stemmed Words:\n",
      "john\n",
      "smith\n",
      ",\n",
      "123\n",
      "main\n",
      "st\n",
      ",\n",
      "anytown\n",
      "usa\n",
      "12345\n",
      "phone\n",
      ":\n",
      "(\n",
      "555\n",
      ")\n",
      "123-4567\n",
      "email\n",
      ":\n",
      "[\n",
      "john.smith\n",
      "@\n",
      "example.com\n",
      "]\n",
      "(\n",
      "mailto\n",
      ":\n",
      "john.smith\n",
      "@\n",
      "example.com\n",
      ")\n",
      "occup\n",
      ":\n",
      "softwar\n",
      "engin\n",
      "jane\n",
      "doe\n",
      ",\n",
      "456\n",
      "elm\n",
      "st\n",
      ",\n",
      "othertown\n",
      "usa\n",
      "67890\n",
      "phone\n",
      ":\n",
      "1-800-789-0123\n",
      "email\n",
      ":\n",
      "janedo\n",
      "@\n",
      "gmail.com\n",
      "occup\n",
      ":\n",
      "market\n",
      "manag\n",
      "\n",
      "Named Entities:\n",
      "PERSON: John \n",
      "GPE: Smith \n",
      "PERSON: Anytown \n",
      "PERSON: Software Engineer Jane Doe \n",
      "PERSON: Othertown \n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "# Download required NLTK data if necessary\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('averaged_perceptron_tagger_eng')\n",
    "nltk.download('maxent_ne_chunker_tab')\n",
    "\n",
    "# use the same text as above\n",
    "# text = \"\"\"\n",
    "# The quick brown fox jumps over the lazy dog. The sun is shining brightly today.\n",
    "# \"\"\"\n",
    "\n",
    "# Tokenize the text into individual words and sentences\n",
    "word_tokens = word_tokenize(text)\n",
    "sentence_tokens = sent_tokenize(text)\n",
    "\n",
    "print(\"Word Tokens:\")\n",
    "for token in word_tokens:\n",
    "    print(token)\n",
    "\n",
    "print(\"\\nSentence Tokens:\")\n",
    "for sentence in sentence_tokens:\n",
    "    print(sentence)\n",
    "\n",
    "# Perform stemming on the tokens\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in word_tokens]\n",
    "\n",
    "print(\"\\nStemmed Words:\")\n",
    "for stemmed_word in stemmed_words:\n",
    "    print(stemmed_word)\n",
    "\n",
    "# Identify named entities in the text\n",
    "tagged_text = nltk.pos_tag(word_tokenize(text))\n",
    "named_entities = ne_chunk(tagged_text)\n",
    "\n",
    "print(\"\\nNamed Entities:\")\n",
    "for tree in named_entities:\n",
    "    if hasattr(tree, 'label'):\n",
    "        print(tree.label(), end=': ')\n",
    "        for leaf in tree.leaves():\n",
    "            print(leaf[0], end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK features used:\n",
    "\n",
    "* Tokenization (`word_tokenize`, `sent_tokenize`)\n",
    "* Stemming (`PorterStemmer`)\n",
    "* Part-of-speech tagging (`pos_tag`)\n",
    "* Named entity recognition (`ne_chunk`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üîó [Natural Language Toolkit](https://www.nltk.org/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
