{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Basic Text Processing**\n",
    "---\n",
    "üìù SALP chapter 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçé An Intriguing Example\n",
    "\n",
    "How do we read and comprehend the text below?\n",
    "- parse sentences, words\n",
    "- search for patterns\n",
    "- recognize name entities\n",
    "- find the meaning of words in their context\n",
    "- feel the sentiment, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "John Smith, 123 Main St, Anytown USA 12345\n",
    "Phone: (555) 123-4567\n",
    "Email: [john.smith@example.com](mailto:john.smith@example.com)\n",
    "Occupation: Software Engineer\n",
    "\n",
    "Jane Doe, 456 Elm St, Othertown USA 67890\n",
    "Phone: 1-800-789-0123\n",
    "Email: janedoe@gmail.com\n",
    "Occupation: Marketing Manager\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can find the following information from this text:\n",
    "\n",
    "* Names (first and last)\n",
    "* Addresses\n",
    "* Phone numbers\n",
    "* Email addresses\n",
    "* Occupations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Names:\n",
      "John Smith\n",
      "Main St\n",
      "Anytown USA\n",
      "Software Engineer\n",
      "Jane Doe\n",
      "Elm St\n",
      "Othertown USA\n",
      "Marketing Manager\n",
      "\n",
      "Addresses:\n",
      "123 Main St, Anytown USA 12345\n",
      "456 Elm St, Othertown USA 67890\n",
      "\n",
      "Phone Numbers:\n",
      "(555) 123-4567\n",
      "0-789-0123\n",
      "\n",
      "Email Addresses:\n",
      "john.smith@example.com\n",
      "john.smith@example.com\n",
      "janedoe@gmail.com\n",
      "\n",
      "Occupations:\n",
      "Software Engineer\n",
      "Marketing Manager\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Define regex patterns for each piece of information\n",
    "name_pattern = r\"[A-Za-z]+ [A-Za-z]+\"\n",
    "address_pattern = r\"\\d+ [A-Za-z]+ St, [A-Za-z]+ USA \\d{5}\"\n",
    "phone_pattern = r\"\\(\\d{3}\\) \\d{3}-\\d{4}|\\d-\\d{3}-\\d{4}\"\n",
    "email_pattern = r\"[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+\"\n",
    "occupation_pattern = r\"Software Engineer|Marketing Manager\"\n",
    "\n",
    "# Use regex to find all occurrences of each pattern\n",
    "names = re.findall(name_pattern, text)\n",
    "addresses = re.findall(address_pattern, text)\n",
    "phones = re.findall(phone_pattern, text)\n",
    "emails = re.findall(email_pattern, text)\n",
    "occupations = re.findall(occupation_pattern, text)\n",
    "\n",
    "# Print the extracted information\n",
    "print(\"Names:\")\n",
    "for name in names:\n",
    "    print(name)\n",
    "\n",
    "print(\"\\nAddresses:\")\n",
    "for address in addresses:\n",
    "    print(address)\n",
    "\n",
    "print(\"\\nPhone Numbers:\")\n",
    "for phone in phones:\n",
    "    print(phone)\n",
    "\n",
    "print(\"\\nEmail Addresses:\")\n",
    "for email in emails:\n",
    "    print(email)\n",
    "\n",
    "print(\"\\nOccupations:\")\n",
    "for occupation in occupations:\n",
    "    print(occupation)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regex features used:\n",
    "\n",
    "* Character classes (`[A-Za-z]+`, `\\d+`)\n",
    "* Word boundaries (`\\b`)\n",
    "* Groups (`(\\d{3})`)\n",
    "* Alternation (`|`)\n",
    "* Quantifiers (`*`, `+`, `{5}`)\n",
    "* Anchors (`^`, `$`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to Regular Expressions\n",
    "* Regular expressions (regex) are a powerful tool for matching patterns in text data.\n",
    "* In NLP, regex is used for tasks such as:\n",
    "\t+ Text preprocessing\n",
    "\t+ Information extraction\n",
    "\t+ Sentiment analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Concepts\n",
    "* **Pattern**: A regular expression is a pattern that matches one or more strings of text.\n",
    "* **Literal characters**: Characters that match themselves (e.g. `a` matches the letter \"a\").\n",
    "* **Metacharacters**: Special characters that have special meanings (e.g. `.` matches any single \n",
    "character).\n",
    "* **Escaping**: Using a backslash (`\\`) to treat metacharacters as literal characters.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Regex Patterns\n",
    "* **Matching a word**: `\\bword\\b` matches the whole word \"word\".\n",
    "\t+ Example: `import re; print(re.search(r'\\bhello\\b', 'hello world'))`\n",
    "* **Matching a digit**: `\\d` matches any single digit.\n",
    "\t+ Example: `import re; print(re.search(r'\\d', 'abc123def'))`\n",
    "* **Matching whitespace**: `\\s` matches any whitespace character (space, tab, newline).\n",
    "\t+ Example: `import re; print(re.search(r'\\s', 'hello world'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Character Classes\n",
    "* **Character class**: A set of characters enclosed in square brackets (`[]`).\n",
    "* **Matching a single character from the class**: `[abc]` matches any one of \"a\", \"b\", or \"c\".\n",
    "\t+ Example: `import re; print(re.search(r'[abc]', 'hello'))`\n",
    "* **Negating a character class**: `[^abc]` matches any single character that is not \"a\", \"b\", or \"c\".\n",
    "\t+ Example: `import re; print(re.search(r'[^abc]', 'hello'))`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantifiers\n",
    "* **Quantifier**: A metacharacter that specifies the number of times a pattern should be matched.\n",
    "* **Matching zero or more occurrences**: `*` matches any number (including zero) of the preceding \n",
    "element.\n",
    "\t+ Example: `import re; print(re.search(r'ab*', 'a'))`\n",
    "* **Matching one or more occurrences**: `+` matches one or more of the preceding element.\n",
    "\t+ Example: `import re; print(re.search(r'ab+', 'ab'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Groups and Capturing\n",
    "* **Group**: A set of characters enclosed in parentheses (`()`).\n",
    "* **Capturing a group**: `(\\w+)` captures one or more word characters as a group.\n",
    "\t+ Example: `import re; print(re.search(r'(\\w+)', 'hello world'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anchors\n",
    "* **Anchor**: A metacharacter that specifies the position of a pattern in a string.\n",
    "* **Matching the start of a string**: `^` matches the start of a string.\n",
    "\t+ Example: `import re; print(re.search(r'^hello', 'hello world'))`\n",
    "* **Matching the end of a string**: `$` matches the end of a string.\n",
    "\t+ Example: `import re; print(re.search(r'world$', 'hello world'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Greedy vs. Lazy Matching\n",
    "* **Greedy matching**: Matches as many characters as possible (default behavior).\n",
    "* **Lazy matching**: Matches as few characters as possible (`?` quantifier).\n",
    "\t+ Example: `import re; print(re.search(r'a.*?b', 'a hello b'))`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Regex in NLP\n",
    "* **Preprocessing text data**: Use regex to remove punctuation, convert to lowercase, etc.\n",
    "* **Extracting information**: Use regex to extract specific patterns from text data (e.g. phone \n",
    "numbers, email addresses).\n",
    "* **Sentiment analysis**: Use regex to extract sentiment-bearing phrases from text data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üçé Example\n",
    "Text Analysis with NLTK:\n",
    "\n",
    "* Tokenize the text into individual words and sentences\n",
    "* Perform stemming on the tokens (i.e., reduce words to their base form)\n",
    "* Identify named entities in the text (e.g., people, places, organizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.chunk import ne_chunk\n",
    "\n",
    "# Download required NLTK data if necessary\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('words')\n",
    "\n",
    "text = \"\"\"\n",
    "The quick brown fox jumps over the lazy dog. The sun is shining brightly today.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize the text into individual words and sentences\n",
    "word_tokens = word_tokenize(text)\n",
    "sentence_tokens = sent_tokenize(text)\n",
    "\n",
    "print(\"Word Tokens:\")\n",
    "for token in word_tokens:\n",
    "    print(token)\n",
    "\n",
    "print(\"\\nSentence Tokens:\")\n",
    "for sentence in sentence_tokens:\n",
    "    print(sentence)\n",
    "\n",
    "# Perform stemming on the tokens\n",
    "stemmer = PorterStemmer()\n",
    "stemmed_words = [stemmer.stem(word) for word in word_tokens]\n",
    "\n",
    "print(\"\\nStemmed Words:\")\n",
    "for stemmed_word in stemmed_words:\n",
    "    print(stemmed_word)\n",
    "\n",
    "# Identify named entities in the text\n",
    "tagged_text = nltk.pos_tag(word_tokenize(text))\n",
    "named_entities = ne_chunk(tagged_text)\n",
    "\n",
    "print(\"\\nNamed Entities:\")\n",
    "for tree in named_entities:\n",
    "    if hasattr(tree, 'label'):\n",
    "        print(tree.label(), end=': ')\n",
    "        for leaf in tree.leaves():\n",
    "            print(leaf[0], end=' ')\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLTK features used:\n",
    "\n",
    "* Tokenization (`word_tokenize`, `sent_tokenize`)\n",
    "* Stemming (`PorterStemmer`)\n",
    "* Part-of-speech tagging (`pos_tag`)\n",
    "* Named entity recognition (`ne_chunk`)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
